<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Árboles de decisión | Introducción al Aprendizaje automático en ciencias de la salud</title>
  <meta name="description" content="6 Árboles de decisión | Introducción al Aprendizaje automático en ciencias de la salud" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Árboles de decisión | Introducción al Aprendizaje automático en ciencias de la salud" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Árboles de decisión | Introducción al Aprendizaje automático en ciencias de la salud" />
  
  
  

<meta name="author" content="Juan R González" />


<meta name="date" content="2023-09-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="caret.html"/>
<link rel="next" href="boosting.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Aprendizaje Automático</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preámbulo</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#instalación-de-librerías-necesarias-para-el-curso"><i class="fa fa-check"></i><b>1.1</b> Instalación de librerías necesarias para el curso</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introducción-al-aprendizaje-automático.html"><a href="introducción-al-aprendizaje-automático.html"><i class="fa fa-check"></i><b>2</b> Introducción al Aprendizaje Automático</a></li>
<li class="chapter" data-level="3" data-path="validación-cruzada.html"><a href="validación-cruzada.html"><i class="fa fa-check"></i><b>3</b> Validación cruzada</a>
<ul>
<li class="chapter" data-level="3.1" data-path="validación-cruzada.html"><a href="validación-cruzada.html#validación-en-un-conjunto-de-datos-externo"><i class="fa fa-check"></i><b>3.1</b> Validación en un conjunto de datos externo</a></li>
<li class="chapter" data-level="3.2" data-path="validación-cruzada.html"><a href="validación-cruzada.html#leave-one-out-cross-validation-loocv"><i class="fa fa-check"></i><b>3.2</b> Leave-one-out cross validation (LOOCV)</a></li>
<li class="chapter" data-level="3.3" data-path="validación-cruzada.html"><a href="validación-cruzada.html#k-fold-cross-validation-k-fold-cv"><i class="fa fa-check"></i><b>3.3</b> K-fold cross validation (K-fold CV)</a></li>
<li class="chapter" data-level="3.4" data-path="validación-cruzada.html"><a href="validación-cruzada.html#uso-de-cv-para-estimar-el-hiper-parámetro"><i class="fa fa-check"></i><b>3.4</b> Uso de CV para estimar el hiper-parámetro</a></li>
<li class="chapter" data-level="3.5" data-path="validación-cruzada.html"><a href="validación-cruzada.html#uso-de-bootstrap"><i class="fa fa-check"></i><b>3.5</b> Uso de bootstrap</a></li>
<li class="chapter" data-level="3.6" data-path="validación-cruzada.html"><a href="validación-cruzada.html#imputación-de-datos-faltantes-información-extra-para-los-que-venís-al-curso"><i class="fa fa-check"></i><b>3.6</b> Imputación de datos faltantes (Información extra para los que venís al curso)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="regresión-logística.html"><a href="regresión-logística.html"><i class="fa fa-check"></i><b>4</b> Regresión logística</a>
<ul>
<li class="chapter" data-level="4.1" data-path="regresión-logística.html"><a href="regresión-logística.html#la-función-logit-inversa"><i class="fa fa-check"></i><b>4.1</b> La función logit inversa</a></li>
<li class="chapter" data-level="4.2" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-de-regresión-logística"><i class="fa fa-check"></i><b>4.2</b> Ejemplo de regresión logística</a></li>
<li class="chapter" data-level="4.3" data-path="regresión-logística.html"><a href="regresión-logística.html#coeficientes-de-regresión-logística-como-probabilidades"><i class="fa fa-check"></i><b>4.3</b> Coeficientes de regresión logística como probabilidades</a></li>
<li class="chapter" data-level="4.4" data-path="regresión-logística.html"><a href="regresión-logística.html#coeficientes-de-regresión-logística-como-razones-de-odds"><i class="fa fa-check"></i><b>4.4</b> Coeficientes de regresión logística como razones de odds</a></li>
<li class="chapter" data-level="4.5" data-path="regresión-logística.html"><a href="regresión-logística.html#capacidad-predictiva-de-un-modelo-de-clasificación"><i class="fa fa-check"></i><b>4.5</b> Capacidad predictiva de un modelo de clasificación</a></li>
<li class="chapter" data-level="4.6" data-path="regresión-logística.html"><a href="regresión-logística.html#ejemplo-de-regresión-logística-modelización-de-riesgo-diabetes"><i class="fa fa-check"></i><b>4.6</b> Ejemplo de regresión logística: modelización de riesgo diabetes</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="regresión-logística.html"><a href="regresión-logística.html#modelo-simple"><i class="fa fa-check"></i><b>4.6.1</b> Modelo simple</a></li>
<li class="chapter" data-level="4.6.2" data-path="regresión-logística.html"><a href="regresión-logística.html#agregar-predictores-y-evaluar-el-ajuste"><i class="fa fa-check"></i><b>4.6.2</b> Agregar predictores y evaluar el ajuste</a></li>
<li class="chapter" data-level="4.6.3" data-path="regresión-logística.html"><a href="regresión-logística.html#análisis-de-interacciones"><i class="fa fa-check"></i><b>4.6.3</b> Análisis de interacciones</a></li>
<li class="chapter" data-level="4.6.4" data-path="regresión-logística.html"><a href="regresión-logística.html#gráfico-de-la-interacción"><i class="fa fa-check"></i><b>4.6.4</b> Gráfico de la interacción</a></li>
<li class="chapter" data-level="4.6.5" data-path="regresión-logística.html"><a href="regresión-logística.html#uso-del-modelo-para-predecir-probabilidades"><i class="fa fa-check"></i><b>4.6.5</b> Uso del modelo para predecir probabilidades</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="regresión-logística.html"><a href="regresión-logística.html#creación-de-un-modelo-y-validación"><i class="fa fa-check"></i><b>4.7</b> Creación de un modelo y validación</a></li>
<li class="chapter" data-level="4.8" data-path="regresión-logística.html"><a href="regresión-logística.html#nomogramas"><i class="fa fa-check"></i><b>4.8</b> Nomogramas</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="caret.html"><a href="caret.html"><i class="fa fa-check"></i><b>5</b> La librería <code>caret</code></a>
<ul>
<li class="chapter" data-level="5.1" data-path="caret.html"><a href="caret.html#pre-procesado"><i class="fa fa-check"></i><b>5.1</b> Pre-procesado</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="caret.html"><a href="caret.html#creación-de-variables"><i class="fa fa-check"></i><b>5.1.1</b> Creación de variables</a></li>
<li class="chapter" data-level="5.1.2" data-path="caret.html"><a href="caret.html#predictores-con-poca-variabilidad"><i class="fa fa-check"></i><b>5.1.2</b> Predictores con poca variabilidad</a></li>
<li class="chapter" data-level="5.1.3" data-path="caret.html"><a href="caret.html#identificación-de-predictores-correlacionados"><i class="fa fa-check"></i><b>5.1.3</b> Identificación de predictores correlacionados</a></li>
<li class="chapter" data-level="5.1.4" data-path="caret.html"><a href="caret.html#centrado-y-escalado"><i class="fa fa-check"></i><b>5.1.4</b> Centrado y escalado</a></li>
<li class="chapter" data-level="5.1.5" data-path="caret.html"><a href="caret.html#imputación"><i class="fa fa-check"></i><b>5.1.5</b> Imputación</a></li>
<li class="chapter" data-level="5.1.6" data-path="caret.html"><a href="caret.html#pre-procesado-con-la-librería-recipes"><i class="fa fa-check"></i><b>5.1.6</b> Pre-procesado con la librería <code>recipes</code></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="caret.html"><a href="caret.html#visualización"><i class="fa fa-check"></i><b>5.2</b> Visualización</a></li>
<li class="chapter" data-level="5.3" data-path="caret.html"><a href="caret.html#ejemplo-completo-creación-de-modelo-diagnóstico-para-cáncer-de-mama"><i class="fa fa-check"></i><b>5.3</b> Ejemplo completo: creación de modelo diagnóstico para cáncer de mama</a></li>
<li class="chapter" data-level="5.4" data-path="caret.html"><a href="caret.html#creación-de-un-modelo-predictivo"><i class="fa fa-check"></i><b>5.4</b> Creación de un modelo predictivo</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html"><i class="fa fa-check"></i><b>6</b> Árboles de decisión</a>
<ul>
<li class="chapter" data-level="6.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#árboles-de-clasificación"><i class="fa fa-check"></i><b>6.1</b> Árboles de clasificación</a></li>
<li class="chapter" data-level="6.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#área-bajo-la-curva-roc"><i class="fa fa-check"></i><b>6.2</b> Área bajo la curva ROC</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#entrenamiento-con-caret"><i class="fa fa-check"></i><b>6.2.1</b> Entrenamiento con <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#árboles-de-regresión"><i class="fa fa-check"></i><b>6.3</b> Árboles de regresión</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#entrenamiento-con-caret-1"><i class="fa fa-check"></i><b>6.3.1</b> Entrenamiento con <code>caret</code></a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#bagged-trees"><i class="fa fa-check"></i><b>6.4</b> Bagged trees</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#bagging-árboles-de-clasificación"><i class="fa fa-check"></i><b>6.4.1</b> Bagging árboles de clasificación</a></li>
<li class="chapter" data-level="6.4.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#bagging-árboles-de-regresión"><i class="fa fa-check"></i><b>6.4.2</b> Bagging árboles de regresión</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#random-forest"><i class="fa fa-check"></i><b>6.5</b> Random Forest</a></li>
<li class="chapter" data-level="6.6" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#random-forest-pn"><i class="fa fa-check"></i><b>6.6</b> Random Forest p&gt;&gt;n</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="boosting.html"><a href="boosting.html"><i class="fa fa-check"></i><b>7</b> Boosting</a>
<ul>
<li class="chapter" data-level="7.1" data-path="boosting.html"><a href="boosting.html#cómo-funciona-el-boosting"><i class="fa fa-check"></i><b>7.1</b> Cómo funciona el <em>boosting</em></a></li>
<li class="chapter" data-level="7.2" data-path="boosting.html"><a href="boosting.html#adaboost"><i class="fa fa-check"></i><b>7.2</b> AdaBoost</a></li>
<li class="chapter" data-level="7.3" data-path="boosting.html"><a href="boosting.html#gbm-básico"><i class="fa fa-check"></i><b>7.3</b> GBM básico</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="boosting.html"><a href="boosting.html#boostingHiperparam"><i class="fa fa-check"></i><b>7.3.1</b> Hiperparámetros</a></li>
<li class="chapter" data-level="7.3.2" data-path="boosting.html"><a href="boosting.html#implementación"><i class="fa fa-check"></i><b>7.3.2</b> Implementación</a></li>
<li class="chapter" data-level="7.3.3" data-path="boosting.html"><a href="boosting.html#estrategia-general-de-tuning"><i class="fa fa-check"></i><b>7.3.3</b> Estrategia general de <em>tuning</em></a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="boosting.html"><a href="boosting.html#gbms-estocásticos"><i class="fa fa-check"></i><b>7.4</b> GBMs estocásticos</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="boosting.html"><a href="boosting.html#hiperparámetros-estocásticos"><i class="fa fa-check"></i><b>7.4.1</b> Hiperparámetros estocásticos</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="boosting.html"><a href="boosting.html#xgboost"><i class="fa fa-check"></i><b>7.5</b> XGBoost</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="boosting.html"><a href="boosting.html#reguralización"><i class="fa fa-check"></i><b>7.5.1</b> Reguralización</a></li>
<li class="chapter" data-level="7.5.2" data-path="boosting.html"><a href="boosting.html#estrategia-de-tuning"><i class="fa fa-check"></i><b>7.5.2</b> Estrategia de <em>tuning</em></a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="boosting.html"><a href="boosting.html#otros-algoritmos-gbm"><i class="fa fa-check"></i><b>7.6</b> Otros algoritmos GBM</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="respuesta-no-balanceada.html"><a href="respuesta-no-balanceada.html"><i class="fa fa-check"></i><b>8</b> Respuesta no balanceada</a></li>
<li class="chapter" data-level="9" data-path="modelos-de-regularización.html"><a href="modelos-de-regularización.html"><i class="fa fa-check"></i><b>9</b> Modelos de regularización</a>
<ul>
<li class="chapter" data-level="9.1" data-path="modelos-de-regularización.html"><a href="modelos-de-regularización.html#introducción"><i class="fa fa-check"></i><b>9.1</b> Introducción</a></li>
<li class="chapter" data-level="9.2" data-path="modelos-de-regularización.html"><a href="modelos-de-regularización.html#cómo-regularizar"><i class="fa fa-check"></i><b>9.2</b> Cómo regularizar</a></li>
<li class="chapter" data-level="9.3" data-path="modelos-de-regularización.html"><a href="modelos-de-regularización.html#implementación-en-r"><i class="fa fa-check"></i><b>9.3</b> Implementación en R</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="modelos-de-regularización.html"><a href="modelos-de-regularización.html#ejemplo-ridge-regression"><i class="fa fa-check"></i><b>9.3.1</b> Ejemplo: Ridge Regression</a></li>
<li class="chapter" data-level="9.3.2" data-path="modelos-de-regularización.html"><a href="modelos-de-regularización.html#ejemplo-lasso"><i class="fa fa-check"></i><b>9.3.2</b> Ejemplo: Lasso</a></li>
<li class="chapter" data-level="9.3.3" data-path="modelos-de-regularización.html"><a href="modelos-de-regularización.html#ejemplo-elastic-net"><i class="fa fa-check"></i><b>9.3.3</b> Ejemplo: Elastic Net</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introducción al Aprendizaje automático en ciencias de la salud</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="árboles-de-decisión" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">6</span> Árboles de decisión<a href="árboles-de-decisión.html#árboles-de-decisión" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Los árboles de decisión, también conocidos como modelos de árbol de clasificación y regresión (CART), son métodos basados en árboles para el aprendizaje automático supervisado. Los árboles de clasificación y de regresión simples son fáciles de usar e interpretar, pero no son competitivos con los mejores métodos de aprendizaje automático. Sin embargo, forman la base para el conjunto de modelos de ensamblaje como “bagged trees”, “random forest” y “boosted trees”, que aunque son menos interpretables, son muy precisos.</p>
<p>Los modelos CART se puede definir en dos tipos de problemas</p>
<ul>
<li><p><strong>Árboles de clasificación:</strong> la variable resultado es categórica y el métodos se utiliza para identificar la “clase” dentro de la cual es más probable que caiga nuestra variable resultado. Un ejemplo de un problema de tipo clasificación sería determinar quién se suscribirá o no a una plataforma digital; o quién se graduará o no de la escuela secundaria; o si una persona tiene cáncer o no.</p></li>
<li><p><strong>Árboles de regressión:</strong> la variable resultado es continua y el métodos se utiliza para predecir su valor. Un ejemplo de un problema de tipo regresión sería predecir los precios de venta de una casa residencial o el nivel de colesterol de una persona.</p></li>
</ul>
<p>Los modelos CART segmentan el espacio predictor en <span class="math inline">\(K\)</span> nodos terminales no superpuestos (hojas). Cada nodo se describe mediante un conjunto de reglas que se pueden utilizar para predecir nuevas respuestas. El valor predicho <span class="math inline">\(\hat{y}\)</span> para cada nodo es la moda (clasificación) o la media (regresión).</p>
<p>Los modelos CART definen los nodos a través de un proceso <em>top-down greedy</em> llamado división binaria recursiva (<em>recursive binary splitting</em>). El proceso es de arriba hacia abajo porque comienza en la parte superior del árbol con todas las observaciones en una sola región y divide sucesivamente el espacio de predicción. Es <em>greedy</em> porque en cada paso de división, la mejor división se realiza en ese paso en particular sin tener en cuenta las divisiones posteriores. La siguiente figura muestra la idea general de esta metodología:</p>
<div class="figure">
<img src="figures/cart.png" style="width:70.0%" alt="" />
<p class="caption">Diagrama árboles de decisión</p>
</div>
<p>Como vemos en el ejemplo una de las <strong>ventajas</strong> de los modelos CART es que consideran interacciones. En este curso no vamos a ver la <strong>regresión lógica</strong> pero es una metodología muy interesante que extiende CART cuando las variables predictoras son binarias y las interacciones que buscamos son del tipo AND y OR. Esta metodología se ha empleado con éxito para analizar <a href="https://academic.oup.com/biostatistics/article/9/1/187/254635">datos genéticos</a> donde el interés radica en saber cuál es el riesgo de desarrolar una enfermeda si te tiene por ejemplo: “una mutación en un punto A del genoma (SNP) y otra mutación en el punto B ó si se tiene una mutación en el punto C pero no se tiene en el punto D.</p>
<p>También son interesantes porque permiten valores faltantes sin la necesidad de hacer imputaciones previas.</p>
<p>La mejor división es la variable predictora y el punto de corte que minimiza una función de costo. La función de costo más común para los árboles de regresión es la suma de los residuos al cuadrado,</p>
<p><span class="math display">\[RSS = \sum_{k=1}^K\sum_{i \in A_k}{\left(y_i - \hat{y}_{A_k} \right)^2}.\]</span>
Para árboles de clasificación, es el índice de Gini,</p>
<p><span class="math display">\[G = \sum_{c=1}^C{\hat{p}_{kc}(1 - \hat{p}_{kc})},\]</span></p>
<p>y la entropía (aka información estadística)</p>
<p><span class="math display">\[D = - \sum_{c=1}^C{\hat{p}_{kc} \log \hat{p}_{kc}}\]</span></p>
<p>dónde <span class="math inline">\(\hat{p}_{kc}\)</span> es la proporción de observaciones de entrenamiento en el nodo <span class="math inline">\(k\)</span> que son de clase <span class="math inline">\(c\)</span>. Un nodo completamente puro en un árbol binario tendría <span class="math inline">\(\hat{p} \in \{ 0, 1 \}\)</span> y <span class="math inline">\(G=D=0\)</span>. Un nodo completamente impuro en un árbol binario tendría <span class="math inline">\(\hat{p}=0.5\)</span> y <span class="math inline">\(G=0.5^2 \cdot 2 = 0.25\)</span> y <span class="math inline">\(D = -(0.5 \log(0.5)) \cdot 2 = 0.69\)</span>.</p>
<p>CART repite el proceso de división para cada nodo hijo hasta que se satisface un criterio de detención, generalmente cuando ningún tamaño de nodo supera un máximo predefinido o la división no mejora el modelo de manera significativa. CART también puede imponer un número mínimo de observaciones en cada nodo.</p>
<p>Es probable que el árbol resultante esté sobre-entrenado (<em>over-fitting</em>) y, por lo tanto, no se generalice bien para los datos de prueba. Para evitar este problema CART <strong>poda el árbol</strong>, minimizando el error de predicción de validación cruzada. En este caso, el hiperparámetro que debermos seleccionar en este modelo es la profundidad del arbol (e.g. número de nodos).</p>
<p>En lugar de realizar una validación cruzada de todos los subárboles posibles para encontrar el que tenga el mínimo de error, CART utiliza la poda de complejidad de costos (<em>cost-complexity pruning</em>). Costo-complejidad es la compensación entre error (costo) y tamaño del árbol (complejidad) donde la compensación se cuantifica con el parámetro costo-complejidad <span class="math inline">\(c_p\)</span>. El costo-complejidad del árbol, <span class="math inline">\(R_{c_p}(T)\)</span>, es la suma de su riesgo (error) más un factor de “complejidad de costos” <span class="math inline">\(c_p\)</span> multiplicado pro el tamaño del arbol <span class="math inline">\(|T|\)</span>.</p>
<p><span class="math display">\[R_{c_p}(T) = R(T) + c_p|T|\]</span></p>
<p><span class="math inline">\(c_p\)</span> puede tomar cualquier valor de <span class="math inline">\([0..\infty]\)</span>, pero resulta que hay un árbol óptimo para rangos de <span class="math inline">\(c_p\)</span>, por lo que solo hay un conjunto finito de valores interesantes para <span class="math inline">\(c_p\)</span> (ver <a href="https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf">Therneau y Atkinson 2019</a>. CART utiliza validación cruzada para determinar qué <span class="math inline">\(c_p\)</span> es óptimo.</p>
<div id="árboles-de-clasificación" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Árboles de clasificación<a href="árboles-de-decisión.html#árboles-de-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Veamos cómo crear árboles de clasificación usando el conjunto de datos <code>ISLR::OJ</code> que se usaron para predecir qué marca de zumo de naranja, Citrus Hill (CH) o Minute Maid = (MM) toman los clientes (variable `Purchase) a partir de 17 variables predictoras.</p>
<p>Vamos a introducir la librería <code>skimr</code> que es interesante para hacer descriptivas. Con ella podremos saber, por ejemplo, cuántos tipos de variables tenemos o ver qué distribuciones tienen las variables continuas</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="árboles-de-decisión.html#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb180-2"><a href="árboles-de-decisión.html#cb180-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb180-3"><a href="árboles-de-decisión.html#cb180-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)  <span class="co"># classification and regression trees </span></span>
<span id="cb180-4"><a href="árboles-de-decisión.html#cb180-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)  <span class="co"># better formatted plots than the ones in rpart</span></span>
<span id="cb180-5"><a href="árboles-de-decisión.html#cb180-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-6"><a href="árboles-de-decisión.html#cb180-6" aria-hidden="true" tabindex="-1"></a>oj_dat <span class="ot">&lt;-</span> ISLR<span class="sc">::</span>OJ</span>
<span id="cb180-7"><a href="árboles-de-decisión.html#cb180-7" aria-hidden="true" tabindex="-1"></a>skimr<span class="sc">::</span><span class="fu">skim</span>(oj_dat)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-102">Table 6.1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">oj_dat</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">1070</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">18</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">2</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">16</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table style="width:100%;">
<colgroup>
<col width="19%" />
<col width="13%" />
<col width="19%" />
<col width="10%" />
<col width="12%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Purchase</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">CH: 653, MM: 417</td>
</tr>
<tr class="even">
<td align="left">Store7</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">No: 714, Yes: 356</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="16%" />
<col width="10%" />
<col width="15%" />
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">WeekofPurchase</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">254.38</td>
<td align="right">15.56</td>
<td align="right">227.00</td>
<td align="right">240.00</td>
<td align="right">257.00</td>
<td align="right">268.00</td>
<td align="right">278.00</td>
<td align="left">▆▅▅▇▇</td>
</tr>
<tr class="even">
<td align="left">StoreID</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.96</td>
<td align="right">2.31</td>
<td align="right">1.00</td>
<td align="right">2.00</td>
<td align="right">3.00</td>
<td align="right">7.00</td>
<td align="right">7.00</td>
<td align="left">▇▅▃▁▇</td>
</tr>
<tr class="odd">
<td align="left">PriceCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.87</td>
<td align="right">0.10</td>
<td align="right">1.69</td>
<td align="right">1.79</td>
<td align="right">1.86</td>
<td align="right">1.99</td>
<td align="right">2.09</td>
<td align="left">▅▂▇▆▁</td>
</tr>
<tr class="even">
<td align="left">PriceMM</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2.09</td>
<td align="right">0.13</td>
<td align="right">1.69</td>
<td align="right">1.99</td>
<td align="right">2.09</td>
<td align="right">2.18</td>
<td align="right">2.29</td>
<td align="left">▂▁▃▇▆</td>
</tr>
<tr class="odd">
<td align="left">DiscCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.05</td>
<td align="right">0.12</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.50</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">DiscMM</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.12</td>
<td align="right">0.21</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.23</td>
<td align="right">0.80</td>
<td align="left">▇▁▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">SpecialCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.15</td>
<td align="right">0.35</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">1.00</td>
<td align="left">▇▁▁▁▂</td>
</tr>
<tr class="even">
<td align="left">SpecialMM</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.16</td>
<td align="right">0.37</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">1.00</td>
<td align="left">▇▁▁▁▂</td>
</tr>
<tr class="odd">
<td align="left">LoyalCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.57</td>
<td align="right">0.31</td>
<td align="right">0.00</td>
<td align="right">0.33</td>
<td align="right">0.60</td>
<td align="right">0.85</td>
<td align="right">1.00</td>
<td align="left">▅▃▆▆▇</td>
</tr>
<tr class="even">
<td align="left">SalePriceMM</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.96</td>
<td align="right">0.25</td>
<td align="right">1.19</td>
<td align="right">1.69</td>
<td align="right">2.09</td>
<td align="right">2.13</td>
<td align="right">2.29</td>
<td align="left">▁▂▂▂▇</td>
</tr>
<tr class="odd">
<td align="left">SalePriceCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.82</td>
<td align="right">0.14</td>
<td align="right">1.39</td>
<td align="right">1.75</td>
<td align="right">1.86</td>
<td align="right">1.89</td>
<td align="right">2.09</td>
<td align="left">▂▁▇▇▅</td>
</tr>
<tr class="even">
<td align="left">PriceDiff</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.15</td>
<td align="right">0.27</td>
<td align="right">-0.67</td>
<td align="right">0.00</td>
<td align="right">0.23</td>
<td align="right">0.32</td>
<td align="right">0.64</td>
<td align="left">▁▂▃▇▂</td>
</tr>
<tr class="odd">
<td align="left">PctDiscMM</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.06</td>
<td align="right">0.10</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.11</td>
<td align="right">0.40</td>
<td align="left">▇▁▂▁▁</td>
</tr>
<tr class="even">
<td align="left">PctDiscCH</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.03</td>
<td align="right">0.06</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.25</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">ListPriceDiff</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.22</td>
<td align="right">0.11</td>
<td align="right">0.00</td>
<td align="right">0.14</td>
<td align="right">0.24</td>
<td align="right">0.30</td>
<td align="right">0.44</td>
<td align="left">▂▃▆▇▁</td>
</tr>
<tr class="even">
<td align="left">STORE</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.63</td>
<td align="right">1.43</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">2.00</td>
<td align="right">3.00</td>
<td align="right">4.00</td>
<td align="left">▇▃▅▅▃</td>
</tr>
</tbody>
</table>
<p>Dividiremos nuestra base de datos <code>oj_dat</code> (n = 1070) en <code>oj_train</code> (80%, n = 857) para estimar varios modelos, y <code>oj_test</code> (20%, n = 213) para comparar su rendimiento con datos nuevos.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="árboles-de-decisión.html#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb181-2"><a href="árboles-de-decisión.html#cb181-2" aria-hidden="true" tabindex="-1"></a>partition <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> oj_dat<span class="sc">$</span>Purchase, <span class="at">p =</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb181-3"><a href="árboles-de-decisión.html#cb181-3" aria-hidden="true" tabindex="-1"></a>oj_train <span class="ot">&lt;-</span> oj_dat[partition, ]</span>
<span id="cb181-4"><a href="árboles-de-decisión.html#cb181-4" aria-hidden="true" tabindex="-1"></a>oj_test <span class="ot">&lt;-</span> oj_dat[<span class="sc">-</span>partition, ]</span></code></pre></div>
<p>La función <code>rpart::rpart()</code> construye un árbol completo, minimizando el índice de Gini <span class="math inline">\(G\)</span> por defecto (<code>parms = list (split = "gini")</code>), hasta que se cumpla el criterio de parada. El criterio de parada predeterminado es:</p>
<ul>
<li>solo intenta una división si el nodo actual tiene al menos <code>minsplit = 20</code> observaciones, y</li>
<li>solo acepta una división si
<ul>
<li>los nodos resultantes tienen al menos <code>minbucket = round (minsplit / 3)</code> observaciones, y</li>
<li>el ajuste general resultante mejora en <code>cp = 0.01</code> (es decir, <span class="math inline">\(\Delta G &lt;= 0.01\)</span>).</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="árboles-de-decisión.html#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Usar method = &quot;class&quot; para clasificación y method = &quot;anova&quot; para regresión</span></span>
<span id="cb182-2"><a href="árboles-de-decisión.html#cb182-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb182-3"><a href="árboles-de-decisión.html#cb182-3" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart_full <span class="ot">&lt;-</span> <span class="fu">rpart</span>(<span class="at">formula =</span> Purchase <span class="sc">~</span> ., <span class="at">data =</span> oj_train, </span>
<span id="cb182-4"><a href="árboles-de-decisión.html#cb182-4" aria-hidden="true" tabindex="-1"></a>                          <span class="at">method =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb182-5"><a href="árboles-de-decisión.html#cb182-5" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart_full</span></code></pre></div>
<pre><code>n= 857 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

 1) root 857 334 CH (0.61026838 0.38973162)  
   2) LoyalCH&gt;=0.48285 537  94 CH (0.82495345 0.17504655)  
     4) LoyalCH&gt;=0.7648795 271  13 CH (0.95202952 0.04797048) *
     5) LoyalCH&lt; 0.7648795 266  81 CH (0.69548872 0.30451128)  
      10) PriceDiff&gt;=-0.165 226  50 CH (0.77876106 0.22123894) *
      11) PriceDiff&lt; -0.165 40   9 MM (0.22500000 0.77500000) *
   3) LoyalCH&lt; 0.48285 320  80 MM (0.25000000 0.75000000)  
     6) LoyalCH&gt;=0.2761415 146  58 MM (0.39726027 0.60273973)  
      12) SalePriceMM&gt;=2.04 71  31 CH (0.56338028 0.43661972) *
      13) SalePriceMM&lt; 2.04 75  18 MM (0.24000000 0.76000000) *
     7) LoyalCH&lt; 0.2761415 174  22 MM (0.12643678 0.87356322) *</code></pre>
<p>La salida comienza con el nodo raíz. La clase predicha en la raíz es <code>CH</code> y esta predicción produce 334 errores en las 857 observaciones para una tasa de éxito (precisión) del 61% y una tasa de error del 39%. Los nodos secundarios del nodo “x” están etiquetados como 2x) y 2x + 1), por lo que los nodos secundarios de 1) son 2) y 3), y los nodos secundarios de 2) son 4) y 5). Los nodos terminales están etiquetados con un asterisco (*).</p>
<p>Sorprendentemente, solo 3 de las 17 variables se utilizaron en el árbol completo: LoyalCH (lealtad de marca del cliente para CH), PriceDiff (precio relativo de MM sobre CH) y SalePriceMM (precio absoluto de MM). La primera división está en LoyalCH = 0.48285. Aquí hay un diagrama del árbol completo (sin podar).</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="árboles-de-decisión.html#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(oj_mdl_cart_full, <span class="at">yesno =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-105-1.png" width="672" /></p>
<p>Las cajas muestran la clasificación del nodo (según la moda), la proporción de observaciones que no son <code>CH</code> y la proporción de observaciones incluidas en el nodo.</p>
<p><code>rpart ()</code> no solo hizo crecer el árbol completo, sino que identificó el conjunto de parámetros de complejidad de costos y midió el rendimiento del modelo de cada árbol correspondiente mediante validación cruzada. <code>printcp ()</code> muestra los posibles valores de <span class="math inline">\(c_p\)</span>. La siguiente tabla se puede utilizar esta tabla para decidir cómo podar el árbol.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="árboles-de-decisión.html#cb185-1" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(oj_mdl_cart_full)</span></code></pre></div>
<pre><code>
Classification tree:
rpart(formula = Purchase ~ ., data = oj_train, method = &quot;class&quot;)

Variables actually used in tree construction:
[1] LoyalCH     PriceDiff   SalePriceMM

Root node error: 334/857 = 0.38973

n= 857 

        CP nsplit rel error  xerror     xstd
1 0.479042      0   1.00000 1.00000 0.042745
2 0.032934      1   0.52096 0.54192 0.035775
3 0.013473      3   0.45509 0.47006 0.033905
4 0.010000      5   0.42814 0.46407 0.033736</code></pre>
<p>Hay 4 valores de <span class="math inline">\(c_p\)</span> en este modelo. El modelo con el parámetro de complejidad más pequeño permite la mayoría de las divisiones (<code>nsplit</code>). El parámetro de mayor complejidad corresponde a un árbol con solo un nodo raíz. <code>rel error</code> es la tasa de error relativa al nodo raíz. El error absoluto del nodo raíz es 0.38973162 (la proporción de MM), por lo que su <code>rel error</code> es 0.38973162 / 0.38973162 = 1.0. Eso significa que el error absoluto del árbol completo (en CP = 0.01) es 0.42814 * 0.38973162 = 0.1669. Podemos verificarlo calculando la tasa de error de los valores predichos:</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="árboles-de-decisión.html#cb187-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_cart_full, <span class="at">newdata =</span> oj_train, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb187-2"><a href="árboles-de-decisión.html#cb187-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(oj_train<span class="sc">$</span>Purchase <span class="sc">!=</span> pred)</span></code></pre></div>
<pre><code>[1] 0.1668611</code></pre>
<p>Para acaber de explicar toda la salida de la table CP, <code>xerror</code> es la tasa de error relativa con validación cruzada y <code>xstd</code> es su error estándar. Si se desea el error más bajo posible, deberíamos podar el árbol con el error de CV relativo más pequeño, <span class="math inline">\(c_p=0.01\)</span>. Si deseamos equilibrar el poder predictivo con la simplicidad, podaremos al árbol más pequeño dentro de 1 SE del que tiene el error relativo más pequeño. La tabla CP no es muy útil para encontrar ese árbol, así que añadiremos una columna para encontrarlo.</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="árboles-de-decisión.html#cb189-1" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart_full<span class="sc">$</span>cptable <span class="sc">%&gt;%</span></span>
<span id="cb189-2"><a href="árboles-de-decisión.html#cb189-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb189-3"><a href="árboles-de-decisión.html#cb189-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">mutate</span>(</span>
<span id="cb189-4"><a href="árboles-de-decisión.html#cb189-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">min_idx =</span> <span class="fu">which.min</span>(oj_mdl_cart_full<span class="sc">$</span>cptable[, <span class="st">&quot;xerror&quot;</span>]),</span>
<span id="cb189-5"><a href="árboles-de-decisión.html#cb189-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">rownum =</span> <span class="fu">row_number</span>(),</span>
<span id="cb189-6"><a href="árboles-de-decisión.html#cb189-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">xerror_cap =</span> oj_mdl_cart_full<span class="sc">$</span>cptable[min_idx, <span class="st">&quot;xerror&quot;</span>] <span class="sc">+</span> </span>
<span id="cb189-7"><a href="árboles-de-decisión.html#cb189-7" aria-hidden="true" tabindex="-1"></a>                   oj_mdl_cart_full<span class="sc">$</span>cptable[min_idx, <span class="st">&quot;xstd&quot;</span>],</span>
<span id="cb189-8"><a href="árboles-de-decisión.html#cb189-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">eval =</span> <span class="fu">case_when</span>(rownum <span class="sc">==</span> min_idx <span class="sc">~</span> <span class="st">&quot;min xerror&quot;</span>,</span>
<span id="cb189-9"><a href="árboles-de-decisión.html#cb189-9" aria-hidden="true" tabindex="-1"></a>                       xerror <span class="sc">&lt;</span> xerror_cap <span class="sc">~</span> <span class="st">&quot;under cap&quot;</span>,</span>
<span id="cb189-10"><a href="árboles-de-decisión.html#cb189-10" aria-hidden="true" tabindex="-1"></a>                       <span class="cn">TRUE</span> <span class="sc">~</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb189-11"><a href="árboles-de-decisión.html#cb189-11" aria-hidden="true" tabindex="-1"></a>   ) <span class="sc">%&gt;%</span></span>
<span id="cb189-12"><a href="árboles-de-decisión.html#cb189-12" aria-hidden="true" tabindex="-1"></a>   dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>rownum, <span class="sc">-</span>min_idx) </span></code></pre></div>
<pre><code>          CP nsplit rel.error    xerror       xstd xerror_cap       eval
1 0.47904192      0 1.0000000 1.0000000 0.04274518  0.4978082           
2 0.03293413      1 0.5209581 0.5419162 0.03577468  0.4978082           
3 0.01347305      3 0.4550898 0.4700599 0.03390486  0.4978082  under cap
4 0.01000000      5 0.4281437 0.4640719 0.03373631  0.4978082 min xerror</code></pre>
<p>El árbol más simple que usa la regla 1-SE es <span class="math inline">\(c_p = 0.01347305\)</span> (error CV = 0.18). Afortunadamente, <code>plotcp ()</code> nos da una representación gráfica de la relación entre <code>xerror</code> y <code>cp</code>.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="árboles-de-decisión.html#cb191-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(oj_mdl_cart_full, <span class="at">upper =</span> <span class="st">&quot;splits&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-109-1.png" width="672" /></p>
<p>La línea discontinua se establece en el mínimo <code>xerror + xstd</code>. El eje superior muestra el número de divisiones en el árbol. NOTA: No estoy seguro de por qué los valores de CP no son los mismos que en la tabla (están cerca, pero no son los mismos). La figura sugiere que debería podar a 5 o 3 divisiones. Vemos que esta curva nunca llega al mínimo, sigue disminuyendo en 5 divisiones. El valor del parámetro de ajuste predeterminado <code>cp = 0.01</code> puede ser demasiado grande, así que lo cambiaremos a <code>cp = 0.001</code> y empezaremos de nuevo.</p>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="árboles-de-decisión.html#cb192-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb192-2"><a href="árboles-de-decisión.html#cb192-2" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart_full <span class="ot">&lt;-</span> <span class="fu">rpart</span>(</span>
<span id="cb192-3"><a href="árboles-de-decisión.html#cb192-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">formula =</span> Purchase <span class="sc">~</span> .,</span>
<span id="cb192-4"><a href="árboles-de-decisión.html#cb192-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> oj_train,</span>
<span id="cb192-5"><a href="árboles-de-decisión.html#cb192-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;class&quot;</span>,</span>
<span id="cb192-6"><a href="árboles-de-decisión.html#cb192-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">cp =</span> <span class="fl">0.001</span></span>
<span id="cb192-7"><a href="árboles-de-decisión.html#cb192-7" aria-hidden="true" tabindex="-1"></a>   )</span>
<span id="cb192-8"><a href="árboles-de-decisión.html#cb192-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(oj_mdl_cart_full)</span></code></pre></div>
<pre><code>n= 857 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

  1) root 857 334 CH (0.61026838 0.38973162)  
    2) LoyalCH&gt;=0.48285 537  94 CH (0.82495345 0.17504655)  
      4) LoyalCH&gt;=0.7648795 271  13 CH (0.95202952 0.04797048) *
      5) LoyalCH&lt; 0.7648795 266  81 CH (0.69548872 0.30451128)  
       10) PriceDiff&gt;=-0.165 226  50 CH (0.77876106 0.22123894)  
         20) ListPriceDiff&gt;=0.255 115  11 CH (0.90434783 0.09565217) *
         21) ListPriceDiff&lt; 0.255 111  39 CH (0.64864865 0.35135135)  
           42) PriceMM&gt;=2.155 19   2 CH (0.89473684 0.10526316) *
           43) PriceMM&lt; 2.155 92  37 CH (0.59782609 0.40217391)  
             86) DiscCH&gt;=0.115 7   0 CH (1.00000000 0.00000000) *
             87) DiscCH&lt; 0.115 85  37 CH (0.56470588 0.43529412)  
              174) ListPriceDiff&gt;=0.215 45  15 CH (0.66666667 0.33333333) *
              175) ListPriceDiff&lt; 0.215 40  18 MM (0.45000000 0.55000000)  
                350) LoyalCH&gt;=0.527571 28  13 CH (0.53571429 0.46428571)  
                  700) WeekofPurchase&lt; 266.5 21   8 CH (0.61904762 0.38095238) *
                  701) WeekofPurchase&gt;=266.5 7   2 MM (0.28571429 0.71428571) *
                351) LoyalCH&lt; 0.527571 12   3 MM (0.25000000 0.75000000) *
       11) PriceDiff&lt; -0.165 40   9 MM (0.22500000 0.77500000) *
    3) LoyalCH&lt; 0.48285 320  80 MM (0.25000000 0.75000000)  
      6) LoyalCH&gt;=0.2761415 146  58 MM (0.39726027 0.60273973)  
       12) SalePriceMM&gt;=2.04 71  31 CH (0.56338028 0.43661972)  
         24) LoyalCH&lt; 0.303104 7   0 CH (1.00000000 0.00000000) *
         25) LoyalCH&gt;=0.303104 64  31 CH (0.51562500 0.48437500)  
           50) WeekofPurchase&gt;=246.5 52  22 CH (0.57692308 0.42307692)  
            100) PriceCH&lt; 1.94 35  11 CH (0.68571429 0.31428571)  
              200) StoreID&lt; 1.5 9   1 CH (0.88888889 0.11111111) *
              201) StoreID&gt;=1.5 26  10 CH (0.61538462 0.38461538)  
                402) LoyalCH&lt; 0.410969 17   4 CH (0.76470588 0.23529412) *
                403) LoyalCH&gt;=0.410969 9   3 MM (0.33333333 0.66666667) *
            101) PriceCH&gt;=1.94 17   6 MM (0.35294118 0.64705882) *
           51) WeekofPurchase&lt; 246.5 12   3 MM (0.25000000 0.75000000) *
       13) SalePriceMM&lt; 2.04 75  18 MM (0.24000000 0.76000000)  
         26) SpecialCH&gt;=0.5 14   6 CH (0.57142857 0.42857143) *
         27) SpecialCH&lt; 0.5 61  10 MM (0.16393443 0.83606557) *
      7) LoyalCH&lt; 0.2761415 174  22 MM (0.12643678 0.87356322)  
       14) LoyalCH&gt;=0.035047 117  21 MM (0.17948718 0.82051282)  
         28) WeekofPurchase&lt; 273.5 104  21 MM (0.20192308 0.79807692)  
           56) PriceCH&gt;=1.875 20   9 MM (0.45000000 0.55000000)  
            112) WeekofPurchase&gt;=252.5 12   5 CH (0.58333333 0.41666667) *
            113) WeekofPurchase&lt; 252.5 8   2 MM (0.25000000 0.75000000) *
           57) PriceCH&lt; 1.875 84  12 MM (0.14285714 0.85714286) *
         29) WeekofPurchase&gt;=273.5 13   0 MM (0.00000000 1.00000000) *
       15) LoyalCH&lt; 0.035047 57   1 MM (0.01754386 0.98245614) *</code></pre>
<p>Este es un árbol mucho más grande. ¿Encontramo un valor <code>cp</code> que produce un mínimo?</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="árboles-de-decisión.html#cb194-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(oj_mdl_cart_full, <span class="at">upper =</span> <span class="st">&quot;splits&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-111-1.png" width="672" /></p>
<p>Sí, el mínimo está en CP = 0.011 con 5 divisiones. El mínimo + 1 SE está en CP = 0.021 con 3 divisiones. Podaremos entonces el árbol en 3.</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="árboles-de-decisión.html#cb195-1" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart <span class="ot">&lt;-</span> <span class="fu">prune</span>(</span>
<span id="cb195-2"><a href="árboles-de-decisión.html#cb195-2" aria-hidden="true" tabindex="-1"></a>   oj_mdl_cart_full,</span>
<span id="cb195-3"><a href="árboles-de-decisión.html#cb195-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">cp =</span> oj_mdl_cart_full<span class="sc">$</span>cptable[oj_mdl_cart_full<span class="sc">$</span>cptable[, <span class="dv">2</span>] <span class="sc">==</span> <span class="dv">3</span>, <span class="st">&quot;CP&quot;</span>]</span>
<span id="cb195-4"><a href="árboles-de-decisión.html#cb195-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb195-5"><a href="árboles-de-decisión.html#cb195-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(oj_mdl_cart, <span class="at">yesno =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-112-1.png" width="672" /></p>
<p>El indicador de compra más “importante” parece ser <code>LoyalCH</code>. De la <a href="https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf">vignette de rpart</a> (página 12) tenemos que:</p>
<pre><code>An overall measure of variable importance is the sum of the goodness of split measures for each split for which it was the primary variable, plus goodness (adjusted agreement) for all splits in which it was a surrogate.</code></pre>
<p>“Surrogate” (variable subrogada[^La FDA define una variable subrogada como “una medida de laboratorio o signo físico que se usa en ensayos terapéuticos como sustituto de una variable clínicamente significativa que es una medida directa sobre lo que siente un paciente, sus funciones o su supervivencia y que se espera que prediga el efecto de la terapia]) se refieren a características alternativas para que un nodo maneje los datos faltantes. Para cada división, CART evalúa una variedad de divisiones alternativas”sustitutas” para usar cuando el valor de la característica para la división principal es NA. Las divisiones sustitutas son divisiones que producen resultados similares a la división original.</p>
<p>La importancia de una variable es la suma de la mejora en la medida general de Gini (o RMSE) producida por los nodos en los que aparece. En el siguiente gráfico podemos ver la importancia de cada variable para este modelo.</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="árboles-de-decisión.html#cb197-1" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart<span class="sc">$</span>variable.importance <span class="sc">%&gt;%</span> </span>
<span id="cb197-2"><a href="árboles-de-decisión.html#cb197-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb197-3"><a href="árboles-de-decisión.html#cb197-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">rownames_to_column</span>(<span class="at">var =</span> <span class="st">&quot;Feature&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb197-4"><a href="árboles-de-decisión.html#cb197-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">rename</span>(<span class="at">Overall =</span> <span class="st">&#39;.&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb197-5"><a href="árboles-de-decisión.html#cb197-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">fct_reorder</span>(Feature, Overall), <span class="at">y =</span> Overall)) <span class="sc">+</span></span>
<span id="cb197-6"><a href="árboles-de-decisión.html#cb197-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_pointrange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> Overall), <span class="at">color =</span> <span class="st">&quot;cadetblue&quot;</span>, <span class="at">size =</span> .<span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb197-7"><a href="árboles-de-decisión.html#cb197-7" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb197-8"><a href="árboles-de-decisión.html#cb197-8" aria-hidden="true" tabindex="-1"></a>   <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb197-9"><a href="árboles-de-decisión.html#cb197-9" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;&quot;</span>, <span class="at">y =</span> <span class="st">&quot;&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Importancia mediante clasificación simple&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-113-1.png" width="672" /></p>
<p><code>LoyalCH</code> es, con mucho, la variable más importante, como se esperaba de su posición en la parte superior del árbol así como en el siguiente nivel abajo.</p>
<p>Podemos ver cómo aparecen los variables subrogadas en el modelo con la función <code>summary()</code>.</p>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="árboles-de-decisión.html#cb198-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(oj_mdl_cart)</span></code></pre></div>
<pre><code>Call:
rpart(formula = Purchase ~ ., data = oj_train, method = &quot;class&quot;, 
    cp = 0.001)
  n= 857 

          CP nsplit rel error    xerror       xstd
1 0.47904192      0 1.0000000 1.0000000 0.04274518
2 0.03293413      1 0.5209581 0.5419162 0.03577468
3 0.01347305      3 0.4550898 0.4700599 0.03390486

Variable importance
       LoyalCH      PriceDiff    SalePriceMM        StoreID WeekofPurchase         DiscMM 
            67              9              5              4              4              3 
       PriceMM      PctDiscMM        PriceCH 
             3              3              1 

Node number 1: 857 observations,    complexity param=0.4790419
  predicted class=CH  expected loss=0.3897316  P(node) =1
    class counts:   523   334
   probabilities: 0.610 0.390 
  left son=2 (537 obs) right son=3 (320 obs)
  Primary splits:
      LoyalCH       &lt; 0.48285   to the right, improve=132.56800, (0 missing)
      StoreID       &lt; 3.5       to the right, improve= 40.12097, (0 missing)
      PriceDiff     &lt; 0.015     to the right, improve= 24.26552, (0 missing)
      ListPriceDiff &lt; 0.255     to the right, improve= 22.79117, (0 missing)
      SalePriceMM   &lt; 1.84      to the right, improve= 20.16447, (0 missing)
  Surrogate splits:
      StoreID        &lt; 3.5       to the right, agree=0.646, adj=0.053, (0 split)
      PriceMM        &lt; 1.89      to the right, agree=0.638, adj=0.031, (0 split)
      WeekofPurchase &lt; 229.5     to the right, agree=0.632, adj=0.016, (0 split)
      DiscMM         &lt; 0.77      to the left,  agree=0.629, adj=0.006, (0 split)
      SalePriceMM    &lt; 1.385     to the right, agree=0.629, adj=0.006, (0 split)

Node number 2: 537 observations,    complexity param=0.03293413
  predicted class=CH  expected loss=0.1750466  P(node) =0.6266044
    class counts:   443    94
   probabilities: 0.825 0.175 
  left son=4 (271 obs) right son=5 (266 obs)
  Primary splits:
      LoyalCH       &lt; 0.7648795 to the right, improve=17.669310, (0 missing)
      PriceDiff     &lt; 0.015     to the right, improve=15.475200, (0 missing)
      SalePriceMM   &lt; 1.84      to the right, improve=13.951730, (0 missing)
      ListPriceDiff &lt; 0.255     to the right, improve=11.407560, (0 missing)
      DiscMM        &lt; 0.15      to the left,  improve= 7.795122, (0 missing)
  Surrogate splits:
      WeekofPurchase &lt; 257.5     to the right, agree=0.594, adj=0.180, (0 split)
      PriceCH        &lt; 1.775     to the right, agree=0.590, adj=0.173, (0 split)
      StoreID        &lt; 3.5       to the right, agree=0.587, adj=0.165, (0 split)
      PriceMM        &lt; 2.04      to the right, agree=0.587, adj=0.165, (0 split)
      SalePriceMM    &lt; 2.04      to the right, agree=0.587, adj=0.165, (0 split)

Node number 3: 320 observations
  predicted class=MM  expected loss=0.25  P(node) =0.3733956
    class counts:    80   240
   probabilities: 0.250 0.750 

Node number 4: 271 observations
  predicted class=CH  expected loss=0.04797048  P(node) =0.3162194
    class counts:   258    13
   probabilities: 0.952 0.048 

Node number 5: 266 observations,    complexity param=0.03293413
  predicted class=CH  expected loss=0.3045113  P(node) =0.3103851
    class counts:   185    81
   probabilities: 0.695 0.305 
  left son=10 (226 obs) right son=11 (40 obs)
  Primary splits:
      PriceDiff     &lt; -0.165    to the right, improve=20.84307, (0 missing)
      ListPriceDiff &lt; 0.235     to the right, improve=20.82404, (0 missing)
      SalePriceMM   &lt; 1.84      to the right, improve=16.80587, (0 missing)
      DiscMM        &lt; 0.15      to the left,  improve=10.05120, (0 missing)
      PctDiscMM     &lt; 0.0729725 to the left,  improve=10.05120, (0 missing)
  Surrogate splits:
      SalePriceMM    &lt; 1.585     to the right, agree=0.906, adj=0.375, (0 split)
      DiscMM         &lt; 0.57      to the left,  agree=0.895, adj=0.300, (0 split)
      PctDiscMM      &lt; 0.264375  to the left,  agree=0.895, adj=0.300, (0 split)
      WeekofPurchase &lt; 274.5     to the left,  agree=0.872, adj=0.150, (0 split)
      SalePriceCH    &lt; 2.075     to the left,  agree=0.857, adj=0.050, (0 split)

Node number 10: 226 observations
  predicted class=CH  expected loss=0.2212389  P(node) =0.2637106
    class counts:   176    50
   probabilities: 0.779 0.221 

Node number 11: 40 observations
  predicted class=MM  expected loss=0.225  P(node) =0.04667445
    class counts:     9    31
   probabilities: 0.225 0.775 </code></pre>
<p>Una vez tenemos un modelo (o varios) los podemos evaluar en la muestra test con las medidas estándard</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="árboles-de-decisión.html#cb200-1" aria-hidden="true" tabindex="-1"></a>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_cart, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;class&quot;</span>) </span>
<span id="cb200-2"><a href="árboles-de-decisión.html#cb200-2" aria-hidden="true" tabindex="-1"></a>oj_cm_cart <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred,  oj_test<span class="sc">$</span>Purchase)</span>
<span id="cb200-3"><a href="árboles-de-decisión.html#cb200-3" aria-hidden="true" tabindex="-1"></a>oj_cm_cart</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  CH  MM
        CH 113  13
        MM  17  70
                                          
               Accuracy : 0.8592          
                 95% CI : (0.8051, 0.9029)
    No Information Rate : 0.6103          
    P-Value [Acc &gt; NIR] : 1.265e-15       
                                          
                  Kappa : 0.7064          
                                          
 Mcnemar&#39;s Test P-Value : 0.5839          
                                          
            Sensitivity : 0.8692          
            Specificity : 0.8434          
         Pos Pred Value : 0.8968          
         Neg Pred Value : 0.8046          
             Prevalence : 0.6103          
         Detection Rate : 0.5305          
   Detection Prevalence : 0.5915          
      Balanced Accuracy : 0.8563          
                                          
       &#39;Positive&#39; Class : CH              
                                          </code></pre>
<p>También podemos representar gráficamente la tabla de confusión</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="árboles-de-decisión.html#cb202-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(oj_test<span class="sc">$</span>Purchase, pred, </span>
<span id="cb202-2"><a href="árboles-de-decisión.html#cb202-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">&quot;Clasificación: Predicho vs. Observado&quot;</span>,</span>
<span id="cb202-3"><a href="árboles-de-decisión.html#cb202-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Observado&quot;</span>,</span>
<span id="cb202-4"><a href="árboles-de-decisión.html#cb202-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">&quot;Predicho&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-116-1.png" width="672" /></p>
</div>
<div id="área-bajo-la-curva-roc" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Área bajo la curva ROC<a href="árboles-de-decisión.html#área-bajo-la-curva-roc" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>También podemos calcular el área bajo la curva ROC. La curva ROC (características operativas del receptor) es otra medida de precisión. Corresponde a un gráfico de la tasa de verdaderos positivos (TPR, sensibilidad) versus la tasa de falsos positivos (FPR, 1 - especificidad) para un conjunto de umbrales. De forma predeterminada, el umbral para predecir la clasificación predeterminada es 0.50, pero podría ser cualquier umbral. La función <code>precrec::evalmod ()</code> calcula los valores de la matriz de confusión del modelo usando el conjunto de datos test. El AUC en el conjunto de datos test es 0.8848 y podemos calcularlo con varias funciones: <code>pROC::plot.roc ()</code>, <code>plotROC::geom_roc ()</code>, <code>yardstick::roc_curve ()</code> y <code>plotROC</code> para usar <code>ggplot()</code> [geometría <code>geom_roc ()</code>].</p>
<p>Nosotros usaremos <code>pROC</code>. Para ello necesitamos tener las predicciones como probabilidades para la categoría de referencia. <strong>NOTA:</strong> El AUC es, pues, una medida útil para casos donde el predictor es binario.</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb203-1"><a href="árboles-de-decisión.html#cb203-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span>
<span id="cb203-2"><a href="árboles-de-decisión.html#cb203-2" aria-hidden="true" tabindex="-1"></a>pred2 <span class="ot">&lt;-</span>  <span class="fu">predict</span>(oj_mdl_cart, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[,<span class="st">&quot;CH&quot;</span>]</span>
<span id="cb203-3"><a href="árboles-de-decisión.html#cb203-3" aria-hidden="true" tabindex="-1"></a>roc.car <span class="ot">&lt;-</span> <span class="fu">roc</span>(oj_test<span class="sc">$</span>Purchase, pred2, <span class="at">print.auc=</span><span class="cn">TRUE</span>, </span>
<span id="cb203-4"><a href="árboles-de-decisión.html#cb203-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">ci=</span><span class="cn">TRUE</span>,</span>
<span id="cb203-5"><a href="árboles-de-decisión.html#cb203-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">plot=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-117-1.png" width="672" /></p>
<div id="entrenamiento-con-caret" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Entrenamiento con <code>caret</code><a href="árboles-de-decisión.html#entrenamiento-con-caret" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>También podemos ajustar el modelo con la función <code>caret::train ()</code>. Recordemo que hay dos formas de ajustar los hiperparámetros cuando usamos <code>train ()</code>:</p>
<ul>
<li>establecer el número de valores de parámetros de ajuste a considerar utilizando <code>tuneLength</code>, o</li>
<li>establecer ciertos valores para cada parámetro utilizando <code>tuneGrid</code>.</li>
</ul>
<p><strong>ESTRATEGIA:</strong> Construiremos el modelo usando una validación cruzada de 10 veces para optimizar el hiperparámetro CP. Si no tenemos idea de cuál es el parámetro de ajuste óptimo, empezaremos con <code>tuneLength</code> para aproximarnos al valor óptimo y luego ajustaremos el valor con <code>tuneGrid</code>. Crearemos un objeto de control de entrenamiento que puedo reutilizar en otras compilaciones de modelos.</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="árboles-de-decisión.html#cb204-1" aria-hidden="true" tabindex="-1"></a>oj_trControl <span class="ot">=</span> <span class="fu">trainControl</span> (<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb204-2"><a href="árboles-de-decisión.html#cb204-2" aria-hidden="true" tabindex="-1"></a>   <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb204-3"><a href="árboles-de-decisión.html#cb204-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">savePredictions =</span> <span class="st">&quot;final&quot;</span>,  <span class="co"># guardaremos preds para el valor óptimo del parámetro a tunear</span></span>
<span id="cb204-4"><a href="árboles-de-decisión.html#cb204-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">classProbs =</span> <span class="cn">TRUE</span>,  <span class="co"># probs para las clases además de preds</span></span>
<span id="cb204-5"><a href="árboles-de-decisión.html#cb204-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">summaryFunction =</span> twoClassSummary</span>
<span id="cb204-6"><a href="árboles-de-decisión.html#cb204-6" aria-hidden="true" tabindex="-1"></a>   )</span></code></pre></div>
<p>Ahora estimamos el modelo con</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="árboles-de-decisión.html#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb205-2"><a href="árboles-de-decisión.html#cb205-2" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart2 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb205-3"><a href="árboles-de-decisión.html#cb205-3" aria-hidden="true" tabindex="-1"></a>   Purchase <span class="sc">~</span> ., </span>
<span id="cb205-4"><a href="árboles-de-decisión.html#cb205-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> oj_train, </span>
<span id="cb205-5"><a href="árboles-de-decisión.html#cb205-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb205-6"><a href="árboles-de-decisión.html#cb205-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb205-7"><a href="árboles-de-decisión.html#cb205-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb205-8"><a href="árboles-de-decisión.html#cb205-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> oj_trControl</span>
<span id="cb205-9"><a href="árboles-de-decisión.html#cb205-9" aria-hidden="true" tabindex="-1"></a>   )</span></code></pre></div>
<p><code>caret</code> construye un árbol completo usando los parámetros predeterminados de <code>rpart</code> que son: índice de división de Gini, al menos 20 observaciones en un nodo para considerar dividirlo, y al menos 6 observaciones en cada nodo. Luego, <code>caret</code> calcula la precisión para cada valor candidato del hiperparámetro (CP). Estos son los resultados:</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="árboles-de-decisión.html#cb206-1" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart2</span></code></pre></div>
<pre><code>CART 

857 samples
 17 predictor
  2 classes: &#39;CH&#39;, &#39;MM&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 772, 772, 771, 770, 771, 771, ... 
Resampling results across tuning parameters:

  cp           ROC        Sens       Spec     
  0.005988024  0.8539885  0.8605225  0.7274510
  0.008982036  0.8502309  0.8568578  0.7334225
  0.013473054  0.8459290  0.8473149  0.7397504
  0.032934132  0.7776483  0.8509071  0.6796791
  0.479041916  0.5878764  0.9201379  0.2556150

ROC was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.005988024.</code></pre>
<p>El segundo CP (0.008982036) produce la mayor precisión. Podemos profundizar en el mejor valor de CP usando un <em>tuning grid</em>.</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="árboles-de-decisión.html#cb208-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb208-2"><a href="árboles-de-decisión.html#cb208-2" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart2 <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb208-3"><a href="árboles-de-decisión.html#cb208-3" aria-hidden="true" tabindex="-1"></a>   Purchase <span class="sc">~</span> ., </span>
<span id="cb208-4"><a href="árboles-de-decisión.html#cb208-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> oj_train, </span>
<span id="cb208-5"><a href="árboles-de-decisión.html#cb208-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb208-6"><a href="árboles-de-decisión.html#cb208-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">cp =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fl">0.001</span>, <span class="at">to =</span> <span class="fl">0.010</span>, <span class="at">length =</span> <span class="dv">11</span>)),  </span>
<span id="cb208-7"><a href="árboles-de-decisión.html#cb208-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb208-8"><a href="árboles-de-decisión.html#cb208-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> oj_trControl</span>
<span id="cb208-9"><a href="árboles-de-decisión.html#cb208-9" aria-hidden="true" tabindex="-1"></a>   )</span>
<span id="cb208-10"><a href="árboles-de-decisión.html#cb208-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(oj_mdl_cart2)</span></code></pre></div>
<pre><code>CART 

857 samples
 17 predictor
  2 classes: &#39;CH&#39;, &#39;MM&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 772, 772, 771, 770, 771, 771, ... 
Resampling results across tuning parameters:

  cp      ROC        Sens       Spec     
  0.0010  0.8513056  0.8529390  0.7182709
  0.0019  0.8528471  0.8529753  0.7213012
  0.0028  0.8524435  0.8510522  0.7302139
  0.0037  0.8533529  0.8510522  0.7421569
  0.0046  0.8540042  0.8491292  0.7333333
  0.0055  0.8543820  0.8567126  0.7334225
  0.0064  0.8539885  0.8605225  0.7274510
  0.0073  0.8521076  0.8625181  0.7335116
  0.0082  0.8521076  0.8625181  0.7335116
  0.0091  0.8502309  0.8568578  0.7334225
  0.0100  0.8507262  0.8510885  0.7424242

ROC was used to select the optimal model using the largest value.
The final value used for the model was cp = 0.0055.</code></pre>
<p>El mejor modelo se consigue con CP = 0.0082. A continuación podemos ver las precisiones de validación cruzada para los valores de CP candidatos.</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="árboles-de-decisión.html#cb210-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(oj_mdl_cart2)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-122-1.png" width="672" /></p>
<p>Estos son los resultados para el modelo final:</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="árboles-de-decisión.html#cb211-1" aria-hidden="true" tabindex="-1"></a>oj_mdl_cart2<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>n= 857 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

  1) root 857 334 CH (0.61026838 0.38973162)  
    2) LoyalCH&gt;=0.48285 537  94 CH (0.82495345 0.17504655)  
      4) LoyalCH&gt;=0.7648795 271  13 CH (0.95202952 0.04797048) *
      5) LoyalCH&lt; 0.7648795 266  81 CH (0.69548872 0.30451128)  
       10) PriceDiff&gt;=-0.165 226  50 CH (0.77876106 0.22123894) *
       11) PriceDiff&lt; -0.165 40   9 MM (0.22500000 0.77500000) *
    3) LoyalCH&lt; 0.48285 320  80 MM (0.25000000 0.75000000)  
      6) LoyalCH&gt;=0.2761415 146  58 MM (0.39726027 0.60273973)  
       12) SalePriceMM&gt;=2.04 71  31 CH (0.56338028 0.43661972)  
         24) LoyalCH&lt; 0.303104 7   0 CH (1.00000000 0.00000000) *
         25) LoyalCH&gt;=0.303104 64  31 CH (0.51562500 0.48437500)  
           50) WeekofPurchase&gt;=246.5 52  22 CH (0.57692308 0.42307692)  
            100) PriceCH&lt; 1.94 35  11 CH (0.68571429 0.31428571) *
            101) PriceCH&gt;=1.94 17   6 MM (0.35294118 0.64705882) *
           51) WeekofPurchase&lt; 246.5 12   3 MM (0.25000000 0.75000000) *
       13) SalePriceMM&lt; 2.04 75  18 MM (0.24000000 0.76000000)  
         26) SpecialCH&gt;=0.5 14   6 CH (0.57142857 0.42857143) *
         27) SpecialCH&lt; 0.5 61  10 MM (0.16393443 0.83606557) *
      7) LoyalCH&lt; 0.2761415 174  22 MM (0.12643678 0.87356322) *</code></pre>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="árboles-de-decisión.html#cb213-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(oj_mdl_cart2<span class="sc">$</span>finalModel)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-124-1.png" width="672" /></p>
<p>Veamos el rendimiento en la muestra test:</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="árboles-de-decisión.html#cb214-1" aria-hidden="true" tabindex="-1"></a>pred3 <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_cart2, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>) </span>
<span id="cb214-2"><a href="árboles-de-decisión.html#cb214-2" aria-hidden="true" tabindex="-1"></a>oj_cm_cart2 <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred3,  oj_test<span class="sc">$</span>Purchase)</span>
<span id="cb214-3"><a href="árboles-de-decisión.html#cb214-3" aria-hidden="true" tabindex="-1"></a>oj_cm_cart2</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  CH  MM
        CH 117  18
        MM  13  65
                                          
               Accuracy : 0.8545          
                 95% CI : (0.7998, 0.8989)
    No Information Rate : 0.6103          
    P-Value [Acc &gt; NIR] : 4.83e-15        
                                          
                  Kappa : 0.6907          
                                          
 Mcnemar&#39;s Test P-Value : 0.4725          
                                          
            Sensitivity : 0.9000          
            Specificity : 0.7831          
         Pos Pred Value : 0.8667          
         Neg Pred Value : 0.8333          
             Prevalence : 0.6103          
         Detection Rate : 0.5493          
   Detection Prevalence : 0.6338          
      Balanced Accuracy : 0.8416          
                                          
       &#39;Positive&#39; Class : CH              
                                          </code></pre>
<p>La precisión es 0.8545, un poco peor que la 0.8592 del método directo. El AUC es 0.916 que es mejor que el obtenido con el método directo.</p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="árboles-de-decisión.html#cb216-1" aria-hidden="true" tabindex="-1"></a>pred4 <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_cart2, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[,<span class="st">&quot;CH&quot;</span>] </span>
<span id="cb216-2"><a href="árboles-de-decisión.html#cb216-2" aria-hidden="true" tabindex="-1"></a>roc.car2 <span class="ot">&lt;-</span> <span class="fu">roc</span>(oj_test<span class="sc">$</span>Purchase, pred4, <span class="at">print.auc=</span><span class="cn">TRUE</span>, </span>
<span id="cb216-3"><a href="árboles-de-decisión.html#cb216-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">ci=</span><span class="cn">TRUE</span>,</span>
<span id="cb216-4"><a href="árboles-de-decisión.html#cb216-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">plot=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-126-1.png" width="672" /></p>
<p>Podemos comparar ambas curvas ROC mediante el <a href="https://www.jstor.org/stable/pdf/2531595.pdf?seq=1">test de DeLong</a></p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="árboles-de-decisión.html#cb217-1" aria-hidden="true" tabindex="-1"></a><span class="fu">roc.test</span>(roc.car, roc.car2)</span></code></pre></div>
<pre><code>
    DeLong&#39;s test for two correlated ROC curves

data:  roc.car and roc.car2
Z = -2.4259, p-value = 0.01527
alternative hypothesis: true difference in AUC is not equal to 0
95 percent confidence interval:
 -0.056801412 -0.006034547
sample estimates:
AUC of roc1 AUC of roc2 
  0.8848471   0.9162651 </code></pre>
<p>Finalmente, podemos crear fácilmente la gráfica de importancia de variables con la función <code>varImp ()</code>. La lealtad a la marca es lo más importante, seguida de la diferencia de precio.</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="árboles-de-decisión.html#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">varImp</span>(oj_mdl_cart2), <span class="at">main=</span><span class="st">&quot;Importancia de variables con CART (caret)&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-128-1.png" width="672" /></p>
<p>Parece que con la estrategia de <code>caret</code> hemos conseguido un mejor modelo predictivo gracias, sobre todo, a la posibilidad de buscar el mejor hiperparámetro haciend <em>fine tuning</em>.</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="árboles-de-decisión.html#cb220-1" aria-hidden="true" tabindex="-1"></a>oj_scoreboard <span class="ot">&lt;-</span> <span class="fu">rbind</span>(</span>
<span id="cb220-2"><a href="árboles-de-decisión.html#cb220-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Single Tree&quot;</span>, </span>
<span id="cb220-3"><a href="árboles-de-decisión.html#cb220-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">Accuracy =</span> oj_cm_cart<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>],</span>
<span id="cb220-4"><a href="árboles-de-decisión.html#cb220-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">ROC =</span> roc.car<span class="sc">$</span>auc),</span>
<span id="cb220-5"><a href="árboles-de-decisión.html#cb220-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Single Tree (caret)&quot;</span>, </span>
<span id="cb220-6"><a href="árboles-de-decisión.html#cb220-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">Accuracy =</span> oj_cm_cart2<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>],</span>
<span id="cb220-7"><a href="árboles-de-decisión.html#cb220-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">ROC =</span> roc.car2<span class="sc">$</span>auc)) <span class="sc">%&gt;%</span> </span>
<span id="cb220-8"><a href="árboles-de-decisión.html#cb220-8" aria-hidden="true" tabindex="-1"></a>   <span class="fu">arrange</span>(<span class="fu">desc</span>(ROC))</span>
<span id="cb220-9"><a href="árboles-de-decisión.html#cb220-9" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(oj_scoreboard, <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modelo</th>
<th align="right">Accuracy</th>
<th align="right">ROC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Single Tree (caret)</td>
<td align="right">0.8544601</td>
<td align="right">0.9162651</td>
</tr>
<tr class="even">
<td align="left">Single Tree</td>
<td align="right">0.8591549</td>
<td align="right">0.8848471</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="árboles-de-regresión" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Árboles de regresión<a href="árboles-de-decisión.html#árboles-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Un árbol de regresión simple se construye de manera similar a un árbol de clasificación simple y, al igual que el árbol de clasificación, rara vez se usan por sí solo (sobre todo en problemas complejos o de big data). De nuevo, basaremos el aprendizaje de esta metodología partiendo de un ejemplo real. Usaremos el conjunto de datos <code>ISLR::Carseats</code> que pretende predecir las ventas de sillitas de niños para coches (variable <code>Sales</code>) en 400 tiendas usando 10 variables que contienen información de las características de las sillas.</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="árboles-de-decisión.html#cb221-1" aria-hidden="true" tabindex="-1"></a>cs_dat <span class="ot">&lt;-</span> ISLR<span class="sc">::</span>Carseats</span>
<span id="cb221-2"><a href="árboles-de-decisión.html#cb221-2" aria-hidden="true" tabindex="-1"></a>skimr<span class="sc">::</span><span class="fu">skim</span>(cs_dat)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-130">Table 6.2: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">cs_dat</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">400</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">11</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">3</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">8</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<colgroup>
<col width="17%" />
<col width="12%" />
<col width="17%" />
<col width="9%" />
<col width="10%" />
<col width="32%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ShelveLoc</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">3</td>
<td align="left">Med: 219, Bad: 96, Goo: 85</td>
</tr>
<tr class="even">
<td align="left">Urban</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Yes: 282, No: 118</td>
</tr>
<tr class="odd">
<td align="left">US</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Yes: 258, No: 142</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="15%" />
<col width="11%" />
<col width="15%" />
<col width="7%" />
<col width="7%" />
<col width="3%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="7%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Sales</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">7.50</td>
<td align="right">2.82</td>
<td align="right">0</td>
<td align="right">5.39</td>
<td align="right">7.49</td>
<td align="right">9.32</td>
<td align="right">16.27</td>
<td align="left">▁▆▇▃▁</td>
</tr>
<tr class="even">
<td align="left">CompPrice</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">124.97</td>
<td align="right">15.33</td>
<td align="right">77</td>
<td align="right">115.00</td>
<td align="right">125.00</td>
<td align="right">135.00</td>
<td align="right">175.00</td>
<td align="left">▁▅▇▃▁</td>
</tr>
<tr class="odd">
<td align="left">Income</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">68.66</td>
<td align="right">27.99</td>
<td align="right">21</td>
<td align="right">42.75</td>
<td align="right">69.00</td>
<td align="right">91.00</td>
<td align="right">120.00</td>
<td align="left">▇▆▇▆▅</td>
</tr>
<tr class="even">
<td align="left">Advertising</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">6.64</td>
<td align="right">6.65</td>
<td align="right">0</td>
<td align="right">0.00</td>
<td align="right">5.00</td>
<td align="right">12.00</td>
<td align="right">29.00</td>
<td align="left">▇▃▃▁▁</td>
</tr>
<tr class="odd">
<td align="left">Population</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">264.84</td>
<td align="right">147.38</td>
<td align="right">10</td>
<td align="right">139.00</td>
<td align="right">272.00</td>
<td align="right">398.50</td>
<td align="right">509.00</td>
<td align="left">▇▇▇▇▇</td>
</tr>
<tr class="even">
<td align="left">Price</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">115.80</td>
<td align="right">23.68</td>
<td align="right">24</td>
<td align="right">100.00</td>
<td align="right">117.00</td>
<td align="right">131.00</td>
<td align="right">191.00</td>
<td align="left">▁▂▇▆▁</td>
</tr>
<tr class="odd">
<td align="left">Age</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">53.32</td>
<td align="right">16.20</td>
<td align="right">25</td>
<td align="right">39.75</td>
<td align="right">54.50</td>
<td align="right">66.00</td>
<td align="right">80.00</td>
<td align="left">▇▆▇▇▇</td>
</tr>
<tr class="even">
<td align="left">Education</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">13.90</td>
<td align="right">2.62</td>
<td align="right">10</td>
<td align="right">12.00</td>
<td align="right">14.00</td>
<td align="right">16.00</td>
<td align="right">18.00</td>
<td align="left">▇▇▃▇▇</td>
</tr>
</tbody>
</table>
<p>De nuevo, partiremos nuestro conjunto de datos <code>cs_dat</code> (n = 400) en <code>cs_train</code> (80%, n = 321) y <code>cs_test</code> (20%, n = 79).</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="árboles-de-decisión.html#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb222-2"><a href="árboles-de-decisión.html#cb222-2" aria-hidden="true" tabindex="-1"></a>partition <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(<span class="at">y =</span> cs_dat<span class="sc">$</span>Sales, <span class="at">p =</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb222-3"><a href="árboles-de-decisión.html#cb222-3" aria-hidden="true" tabindex="-1"></a>cs_train <span class="ot">&lt;-</span> cs_dat[partition, ]</span>
<span id="cb222-4"><a href="árboles-de-decisión.html#cb222-4" aria-hidden="true" tabindex="-1"></a>cs_test <span class="ot">&lt;-</span> cs_dat[<span class="sc">-</span>partition, ]</span></code></pre></div>
<p>El primer paso es construir un árbol completo y luego realizar una validación cruzada para ayudar a seleccionar la complejidad de costo óptima (cp). La única diferencia ahora es que usaremos <code>method = "anova"</code> en la función <code>rpart ()</code> para poder estimar un árbol de regresión.</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="árboles-de-decisión.html#cb223-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb223-2"><a href="árboles-de-decisión.html#cb223-2" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart_full <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Sales <span class="sc">~</span> ., cs_train, <span class="at">method =</span> <span class="st">&quot;anova&quot;</span>)</span>
<span id="cb223-3"><a href="árboles-de-decisión.html#cb223-3" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart_full</span></code></pre></div>
<pre><code>n= 321 

node), split, n, deviance, yval
      * denotes terminal node

 1) root 321 2567.76800  7.535950  
   2) ShelveLoc=Bad,Medium 251 1474.14100  6.770359  
     4) Price&gt;=105.5 168  719.70630  5.987024  
       8) ShelveLoc=Bad 50  165.70160  4.693600  
        16) Population&lt; 201.5 20   48.35505  3.646500 *
        17) Population&gt;=201.5 30   80.79922  5.391667 *
       9) ShelveLoc=Medium 118  434.91370  6.535085  
        18) Advertising&lt; 11.5 88  290.05490  6.113068  
          36) CompPrice&lt; 142 69  193.86340  5.769420  
            72) Price&gt;=132.5 16   50.75440  4.455000 *
            73) Price&lt; 132.5 53  107.12060  6.166226 *
          37) CompPrice&gt;=142 19   58.45118  7.361053 *
        19) Advertising&gt;=11.5 30   83.21323  7.773000 *
     5) Price&lt; 105.5 83  442.68920  8.355904  
      10) Age&gt;=63.5 32  153.42300  6.922500  
        20) Price&gt;=85 25   66.89398  6.160800  
          40) ShelveLoc=Bad 9   18.39396  4.772222 *
          41) ShelveLoc=Medium 16   21.38544  6.941875 *
        21) Price&lt; 85 7   20.22194  9.642857 *
      11) Age&lt; 63.5 51  182.26350  9.255294  
        22) Income&lt; 57.5 12   28.03042  7.707500 *
        23) Income&gt;=57.5 39  116.63950  9.731538  
          46) Age&gt;=50.5 14   21.32597  8.451429 *
          47) Age&lt; 50.5 25   59.52474 10.448400 *
   3) ShelveLoc=Good 70  418.98290 10.281140  
     6) Price&gt;=107.5 49  242.58730  9.441633  
      12) Advertising&lt; 13.5 41  162.47820  8.926098  
        24) Age&gt;=61 17   53.37051  7.757647 *
        25) Age&lt; 61 24   69.45776  9.753750 *
      13) Advertising&gt;=13.5 8   13.36599 12.083750 *
     7) Price&lt; 107.5 21   61.28200 12.240000 *</code></pre>
<p>Las ventas pronosticadas en la raíz son las ventas medias para el conjunto de datos de entrenamiento, 7.5 (los valores corresponden a miles de dolares). La primera división está en <code>ShelveLoc = [Bad, Medium]</code> vs <code>Good</code> (calidad). Aquí está el diagrama de árbol sin podar.</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="árboles-de-decisión.html#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(cs_mdl_cart_full, <span class="at">yesno =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-133-1.png" width="672" /></p>
<p>Cada caja muestra el valor predicho del nodo (media) y la proporción de observaciones que están en el nodo (o nodos secundarios).</p>
<p><code>rpart ()</code> estima el árbol completo y utiliza validación cruzada para probar el rendimiento de los posibles hiperparámetros de complejidad. Como antes, <code>printcp ()</code> muestra los valores de cp candidatos que pueden verse en esta tabla. Estos datos pueden ser utilizados para decidir cómo podar el árbol.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="árboles-de-decisión.html#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="fu">printcp</span>(cs_mdl_cart_full)</span></code></pre></div>
<pre><code>
Regression tree:
rpart(formula = Sales ~ ., data = cs_train, method = &quot;anova&quot;)

Variables actually used in tree construction:
[1] Advertising Age         CompPrice   Income      Population  Price       ShelveLoc  

Root node error: 2567.8/321 = 7.9993

n= 321 

         CP nsplit rel error  xerror     xstd
1  0.262736      0   1.00000 1.00635 0.076664
2  0.121407      1   0.73726 0.74888 0.058981
3  0.046379      2   0.61586 0.65278 0.050839
4  0.044830      3   0.56948 0.67245 0.051638
5  0.041671      4   0.52465 0.66230 0.051065
6  0.025993      5   0.48298 0.62345 0.049368
7  0.025823      6   0.45698 0.61980 0.048026
8  0.024007      7   0.43116 0.62058 0.048213
9  0.015441      8   0.40715 0.58061 0.041738
10 0.014698      9   0.39171 0.56413 0.041368
11 0.014641     10   0.37701 0.56277 0.041271
12 0.014233     11   0.36237 0.56081 0.041097
13 0.014015     12   0.34814 0.55647 0.038308
14 0.013938     13   0.33413 0.55647 0.038308
15 0.010560     14   0.32019 0.57110 0.038872
16 0.010000     15   0.30963 0.56676 0.038090</code></pre>
<p>Hay 16 posibles valores de cp en este modelo. El modelo con el parámetro de complejidad más pequeño permite la mayoría de las divisiones (nsplit). El parámetro de mayor complejidad corresponde a un árbol con solo un nodo raíz. <code>rel error</code> es el SSE relativo al nodo raíz. El SSE del nodo raíz es 2567.76800, por lo que su error rel es 2567.76800 / 2567.76800 = 1.0. Eso significa que el error absoluto del árbol completo (en CP = 0.01) es 0.30963 * 2567.76800 = 795.058. Podemos verificar estos resultados calculando el SSE de los valores predichos del modelo:</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="árboles-de-decisión.html#cb228-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">pred =</span> <span class="fu">predict</span>(cs_mdl_cart_full, <span class="at">newdata =</span> cs_train)) <span class="sc">%&gt;%</span></span>
<span id="cb228-2"><a href="árboles-de-decisión.html#cb228-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">mutate</span>(<span class="at">obs =</span> cs_train<span class="sc">$</span>Sales,</span>
<span id="cb228-3"><a href="árboles-de-decisión.html#cb228-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">sq_err =</span> (obs <span class="sc">-</span> pred)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb228-4"><a href="árboles-de-decisión.html#cb228-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">summarise</span>(<span class="at">sse =</span> <span class="fu">sum</span>(sq_err))</span></code></pre></div>
<pre><code>       sse
1 795.0525</code></pre>
<p>La tabla también muestra, <code>xerror</code> que corresponde al SSE con validación cruzada y <code>xstd</code> a su error estándar. Si deseamos el error más bajo posible, podaremos el árbol con el SSE relativo más pequeño (<code>xerror</code>). Si deseamos equilibrar el poder predictivo con la simplicidad, podaremos al árbol más pequeño que esté dentro de 1 SE para el SSE relativo más pequeño. Al igual que en la sección anterior, la tabla CP no es muy útil para encontrar ese árbol, por lo que debemos añadir una columna para visualizar dicha información:</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="árboles-de-decisión.html#cb230-1" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart_full<span class="sc">$</span>cptable <span class="sc">%&gt;%</span></span>
<span id="cb230-2"><a href="árboles-de-decisión.html#cb230-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb230-3"><a href="árboles-de-decisión.html#cb230-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">mutate</span>(<span class="at">min_xerror_idx =</span> <span class="fu">which.min</span>(cs_mdl_cart_full<span class="sc">$</span>cptable[, <span class="st">&quot;xerror&quot;</span>]),</span>
<span id="cb230-4"><a href="árboles-de-decisión.html#cb230-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">rownum =</span> <span class="fu">row_number</span>(),</span>
<span id="cb230-5"><a href="árboles-de-decisión.html#cb230-5" aria-hidden="true" tabindex="-1"></a>          <span class="at">xerror_cap =</span> cs_mdl_cart_full<span class="sc">$</span>cptable[min_xerror_idx, <span class="st">&quot;xerror&quot;</span>] <span class="sc">+</span> </span>
<span id="cb230-6"><a href="árboles-de-decisión.html#cb230-6" aria-hidden="true" tabindex="-1"></a>             cs_mdl_cart_full<span class="sc">$</span>cptable[min_xerror_idx, <span class="st">&quot;xstd&quot;</span>],</span>
<span id="cb230-7"><a href="árboles-de-decisión.html#cb230-7" aria-hidden="true" tabindex="-1"></a>          <span class="at">eval =</span> <span class="fu">case_when</span>(rownum <span class="sc">==</span> min_xerror_idx <span class="sc">~</span> <span class="st">&quot;min xerror&quot;</span>,</span>
<span id="cb230-8"><a href="árboles-de-decisión.html#cb230-8" aria-hidden="true" tabindex="-1"></a>                           xerror <span class="sc">&lt;</span> xerror_cap <span class="sc">~</span> <span class="st">&quot;under cap&quot;</span>,</span>
<span id="cb230-9"><a href="árboles-de-decisión.html#cb230-9" aria-hidden="true" tabindex="-1"></a>                           <span class="cn">TRUE</span> <span class="sc">~</span> <span class="st">&quot;&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb230-10"><a href="árboles-de-decisión.html#cb230-10" aria-hidden="true" tabindex="-1"></a>   dplyr<span class="sc">::</span><span class="fu">select</span>(<span class="sc">-</span>rownum, <span class="sc">-</span>min_xerror_idx) </span></code></pre></div>
<pre><code>           CP nsplit rel.error    xerror       xstd xerror_cap       eval
1  0.26273578      0 1.0000000 1.0063530 0.07666355  0.5947744           
2  0.12140705      1 0.7372642 0.7488767 0.05898146  0.5947744           
3  0.04637919      2 0.6158572 0.6527823 0.05083938  0.5947744           
4  0.04483023      3 0.5694780 0.6724529 0.05163819  0.5947744           
5  0.04167149      4 0.5246478 0.6623028 0.05106530  0.5947744           
6  0.02599265      5 0.4829763 0.6234457 0.04936799  0.5947744           
7  0.02582284      6 0.4569836 0.6198034 0.04802643  0.5947744           
8  0.02400748      7 0.4311608 0.6205756 0.04821332  0.5947744           
9  0.01544139      8 0.4071533 0.5806072 0.04173785  0.5947744  under cap
10 0.01469771      9 0.3917119 0.5641331 0.04136793  0.5947744  under cap
11 0.01464055     10 0.3770142 0.5627713 0.04127139  0.5947744  under cap
12 0.01423309     11 0.3623736 0.5608073 0.04109662  0.5947744  under cap
13 0.01401541     12 0.3481405 0.5564663 0.03830810  0.5947744 min xerror
14 0.01393771     13 0.3341251 0.5564663 0.03830810  0.5947744  under cap
15 0.01055959     14 0.3201874 0.5710951 0.03887227  0.5947744  under cap
16 0.01000000     15 0.3096278 0.5667561 0.03808991  0.5947744  under cap</code></pre>
<p>Bien, entonces el árbol más simple es el que tiene CP = 0.02599265 (5 divisiones). También podemos usar <code>plotcp () para visualizar la relación entre</code>xerror<code>y</code>cp`.</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="árboles-de-decisión.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotcp</span>(cs_mdl_cart_full, <span class="at">upper =</span> <span class="st">&quot;splits&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-137-1.png" width="672" /></p>
<p>La línea discontinua se establece en el mínimo <code>xerror + xstd</code>. El eje superior muestra el número de divisiones en el árbol. El error relativo más pequeño está en CP = 0.01 (15 divisiones), pero el CP máximo debajo de la línea discontinua (una desviación estándar por encima del error mínimo) está en CP = 0.02599265 (5 divisiones). Utilizamos entonces la función <code>prune ()</code> para podar el árbol especificando el coste-complejidad asociado a este CP.</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="árboles-de-decisión.html#cb233-1" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart <span class="ot">&lt;-</span> <span class="fu">prune</span>(</span>
<span id="cb233-2"><a href="árboles-de-decisión.html#cb233-2" aria-hidden="true" tabindex="-1"></a>   cs_mdl_cart_full,</span>
<span id="cb233-3"><a href="árboles-de-decisión.html#cb233-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">cp =</span> cs_mdl_cart_full<span class="sc">$</span>cptable[cs_mdl_cart_full<span class="sc">$</span>cptable[, <span class="dv">2</span>] <span class="sc">==</span> <span class="dv">5</span>, <span class="st">&quot;CP&quot;</span>]</span>
<span id="cb233-4"><a href="árboles-de-decisión.html#cb233-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb233-5"><a href="árboles-de-decisión.html#cb233-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(cs_mdl_cart, <span class="at">yesno =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-138-1.png" width="672" /></p>
<p>El indicador más “importante” de ventas es <code>ShelveLoc</code>. Estos son los valores de importancia del modelo:</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="árboles-de-decisión.html#cb234-1" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart<span class="sc">$</span>variable.importance <span class="sc">%&gt;%</span> </span>
<span id="cb234-2"><a href="árboles-de-decisión.html#cb234-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb234-3"><a href="árboles-de-decisión.html#cb234-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">rownames_to_column</span>(<span class="at">var =</span> <span class="st">&quot;Feature&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb234-4"><a href="árboles-de-decisión.html#cb234-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">rename</span>(<span class="at">Overall =</span> <span class="st">&#39;.&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb234-5"><a href="árboles-de-decisión.html#cb234-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">fct_reorder</span>(Feature, Overall), <span class="at">y =</span> Overall)) <span class="sc">+</span></span>
<span id="cb234-6"><a href="árboles-de-decisión.html#cb234-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_pointrange</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> Overall), <span class="at">color =</span> <span class="st">&quot;cadetblue&quot;</span>, <span class="at">size =</span> .<span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb234-7"><a href="árboles-de-decisión.html#cb234-7" aria-hidden="true" tabindex="-1"></a>   <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb234-8"><a href="árboles-de-decisión.html#cb234-8" aria-hidden="true" tabindex="-1"></a>   <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb234-9"><a href="árboles-de-decisión.html#cb234-9" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;&quot;</span>, <span class="at">y =</span> <span class="st">&quot;&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Variable Importance with Simple Regression&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-139-1.png" width="672" /></p>
<p>El indicador más importante de ventas es <code>ShelveLoc</code>, luego <code>Price</code>, luego <code>Age</code> (edad media de la población donde está la tienda). Todas estas variables aparecen en el modelo final. <code>CompPrice</code> (precio del competidor) también es relevante.</p>
<p>El último paso es hacer predicciones sobre el conjunto de datos de validación. Cuando la variable respuesta es continua usamos:</p>
<ul>
<li><p>la raíz del error cuadrático medio <span class="math inline">\(RMSE = \sqrt{(1/2) \sum{(actual - pred)^2}})\)</span> y</p></li>
<li><p>el errr absoluto medio <span class="math inline">\(MAE = (1/n) \sum{|actual - pred|}\)</span></p></li>
</ul>
<p>La diferencia entre ambos es que RMSE penaliza más los errores grandes. Para un árbol de regresión, basta con indicar <code>type="vector")  en la función</code>predict ()` (que es el valor por defecto).</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="árboles-de-decisión.html#cb235-1" aria-hidden="true" tabindex="-1"></a>cs_preds_cart <span class="ot">&lt;-</span> <span class="fu">predict</span>(cs_mdl_cart, cs_test, <span class="at">type =</span> <span class="st">&quot;vector&quot;</span>)</span>
<span id="cb235-2"><a href="árboles-de-decisión.html#cb235-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-3"><a href="árboles-de-decisión.html#cb235-3" aria-hidden="true" tabindex="-1"></a>cs_rmse_cart <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(</span>
<span id="cb235-4"><a href="árboles-de-decisión.html#cb235-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">pred =</span> cs_preds_cart,</span>
<span id="cb235-5"><a href="árboles-de-decisión.html#cb235-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">obs =</span> cs_test<span class="sc">$</span>Sales</span>
<span id="cb235-6"><a href="árboles-de-decisión.html#cb235-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb235-7"><a href="árboles-de-decisión.html#cb235-7" aria-hidden="true" tabindex="-1"></a>cs_rmse_cart</span></code></pre></div>
<pre><code>[1] 2.363202</code></pre>
<p>El proceso de poda conduce a un error de predicción promedio de 2.363 en el conjunto de datos de prueba. No está mal considerando que la desviación estándar de la variable <code>Sales</code> es 2.8. Podemos visualizar la relación entre los datos predichos y los observados mediante:</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="árboles-de-decisión.html#cb237-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">Predichos =</span> cs_preds_cart, <span class="at">Observados =</span> cs_test<span class="sc">$</span>Sales) <span class="sc">%&gt;%</span></span>
<span id="cb237-2"><a href="árboles-de-decisión.html#cb237-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Observados, <span class="at">y =</span> Predichos)) <span class="sc">+</span></span>
<span id="cb237-3"><a href="árboles-de-decisión.html#cb237-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">&quot;cadetblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb237-4"><a href="árboles-de-decisión.html#cb237-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>() <span class="sc">+</span></span>
<span id="cb237-5"><a href="árboles-de-decisión.html#cb237-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb237-6"><a href="árboles-de-decisión.html#cb237-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Carseats CART, predichos vs observados&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-141-1.png" width="672" /></p>
<div id="entrenamiento-con-caret-1" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Entrenamiento con <code>caret</code><a href="árboles-de-decisión.html#entrenamiento-con-caret-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>También podemos ajustar el modelo con <code>caret::train ()</code> especificando <code>method = "rpart"</code>. Construirmos el modelo usando 10-fold CV para optimizar el hiperparámetro CP.</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="árboles-de-decisión.html#cb238-1" aria-hidden="true" tabindex="-1"></a>cs_trControl <span class="ot">=</span> <span class="fu">trainControl</span>(</span>
<span id="cb238-2"><a href="árboles-de-decisión.html#cb238-2" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb238-3"><a href="árboles-de-decisión.html#cb238-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb238-4"><a href="árboles-de-decisión.html#cb238-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">savePredictions =</span> <span class="st">&quot;final&quot;</span> </span>
<span id="cb238-5"><a href="árboles-de-decisión.html#cb238-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Usaremos la misma estrategia que en el caso de los árboles de clasificación,
dejaremos que el modelo busque el mejor parámetro de ajuste de CP con <code>tuneLength</code> y luego lo ajustaremos con <code>tuneGrid</code>.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="árboles-de-decisión.html#cb239-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb239-2"><a href="árboles-de-decisión.html#cb239-2" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart2 <span class="ot">=</span> <span class="fu">train</span>(</span>
<span id="cb239-3"><a href="árboles-de-decisión.html#cb239-3" aria-hidden="true" tabindex="-1"></a>   Sales <span class="sc">~</span> ., </span>
<span id="cb239-4"><a href="árboles-de-decisión.html#cb239-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> cs_train, </span>
<span id="cb239-5"><a href="árboles-de-decisión.html#cb239-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb239-6"><a href="árboles-de-decisión.html#cb239-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">tuneLength =</span> <span class="dv">5</span>,</span>
<span id="cb239-7"><a href="árboles-de-decisión.html#cb239-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;RMSE&quot;</span>,</span>
<span id="cb239-8"><a href="árboles-de-decisión.html#cb239-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> cs_trControl</span>
<span id="cb239-9"><a href="árboles-de-decisión.html#cb239-9" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="árboles-de-decisión.html#cb240-1" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart2</span></code></pre></div>
<pre><code>CART 

321 samples
 10 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 289, 289, 289, 289, 289, 289, ... 
Resampling results across tuning parameters:

  cp          RMSE      Rsquared   MAE     
  0.04167149  2.209383  0.4065251  1.778797
  0.04483023  2.243618  0.3849728  1.805027
  0.04637919  2.275563  0.3684309  1.808814
  0.12140705  2.400455  0.2942663  1.936927
  0.26273578  2.692867  0.1898998  2.192774

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.04167149.</code></pre>
<p>El primer cp (0.04167149) presenta el RMSE más pequeño. Puedemos hacer una búsqueda más fina para mejorar el valor de cp usando un <em>grid</em>:</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="árboles-de-decisión.html#cb242-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb242-2"><a href="árboles-de-decisión.html#cb242-2" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart2 <span class="ot">=</span> <span class="fu">train</span>(</span>
<span id="cb242-3"><a href="árboles-de-decisión.html#cb242-3" aria-hidden="true" tabindex="-1"></a>   Sales <span class="sc">~</span> ., </span>
<span id="cb242-4"><a href="árboles-de-decisión.html#cb242-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> cs_train, </span>
<span id="cb242-5"><a href="árboles-de-decisión.html#cb242-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb242-6"><a href="árboles-de-decisión.html#cb242-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">cp =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="fl">0.1</span>, <span class="at">by =</span> <span class="fl">0.01</span>)),</span>
<span id="cb242-7"><a href="árboles-de-decisión.html#cb242-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;RMSE&quot;</span>,</span>
<span id="cb242-8"><a href="árboles-de-decisión.html#cb242-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> cs_trControl</span>
<span id="cb242-9"><a href="árboles-de-decisión.html#cb242-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb242-10"><a href="árboles-de-decisión.html#cb242-10" aria-hidden="true" tabindex="-1"></a>cs_mdl_cart2</span></code></pre></div>
<pre><code>CART 

321 samples
 10 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 289, 289, 289, 289, 289, 289, ... 
Resampling results across tuning parameters:

  cp    RMSE      Rsquared   MAE     
  0.00  2.055676  0.5027431  1.695453
  0.01  2.135096  0.4642577  1.745937
  0.02  2.095767  0.4733269  1.699235
  0.03  2.131246  0.4534544  1.690453
  0.04  2.146886  0.4411380  1.712705
  0.05  2.284937  0.3614130  1.837782
  0.06  2.265498  0.3709523  1.808319
  0.07  2.282630  0.3597216  1.836227
  0.08  2.282630  0.3597216  1.836227
  0.09  2.282630  0.3597216  1.836227
  0.10  2.282630  0.3597216  1.836227

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was cp = 0.</code></pre>
<p>En este ejemplo, parece que el árbol con mejor rendimiento es el que no ha sido podado.</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="árboles-de-decisión.html#cb244-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cs_mdl_cart2)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-146-1.png" width="672" /></p>
<p>Este sería el modelo final</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="árboles-de-decisión.html#cb245-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(cs_mdl_cart2<span class="sc">$</span>finalModel)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-147-1.png" width="672" /></p>
<p>y estas las variables más importantes</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="árboles-de-decisión.html#cb246-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">varImp</span>(cs_mdl_cart2), <span class="at">main=</span><span class="st">&quot;Importancia de variables para Regresión&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-148-1.png" width="672" /></p>
<p>Como siempre, debemos evaluar el modelo en nuestra muestra test:</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="árboles-de-decisión.html#cb247-1" aria-hidden="true" tabindex="-1"></a>cs_preds_cart2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(cs_mdl_cart2, cs_test, <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>)</span>
<span id="cb247-2"><a href="árboles-de-decisión.html#cb247-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(<span class="at">Actual =</span> cs_test<span class="sc">$</span>Sales, <span class="at">Predicted =</span> cs_preds_cart2) <span class="sc">%&gt;%</span></span>
<span id="cb247-3"><a href="árboles-de-decisión.html#cb247-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Actual, <span class="at">y =</span> Predicted)) <span class="sc">+</span></span>
<span id="cb247-4"><a href="árboles-de-decisión.html#cb247-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">&quot;cadetblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb247-5"><a href="árboles-de-decisión.html#cb247-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="at">formula =</span> <span class="st">&quot;y ~ x&quot;</span>) <span class="sc">+</span></span>
<span id="cb247-6"><a href="árboles-de-decisión.html#cb247-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb247-7"><a href="árboles-de-decisión.html#cb247-7" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Carseats CART, Predicted vs Actual (caret)&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-149-1.png" width="672" /></p>
<p>Observamos como el modelo sobreestima en el extremo inferior y subestima en el extremo superior. Podemos calcular el RMSE para estos datos:</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="árboles-de-decisión.html#cb248-1" aria-hidden="true" tabindex="-1"></a>(cs_rmse_cart2 <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(<span class="at">pred =</span> cs_preds_cart2, <span class="at">obs =</span> cs_test<span class="sc">$</span>Sales))</span></code></pre></div>
<pre><code>[1] 2.298331</code></pre>
<p>Caret mejora las predicciones:</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="árboles-de-decisión.html#cb250-1" aria-hidden="true" tabindex="-1"></a>cs_scoreboard <span class="ot">&lt;-</span> <span class="fu">rbind</span>(</span>
<span id="cb250-2"><a href="árboles-de-decisión.html#cb250-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Single Tree&quot;</span>, <span class="at">RMSE =</span> cs_rmse_cart),</span>
<span id="cb250-3"><a href="árboles-de-decisión.html#cb250-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Single Tree (caret)&quot;</span>, <span class="at">RMSE =</span> cs_rmse_cart2)</span>
<span id="cb250-4"><a href="árboles-de-decisión.html#cb250-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(RMSE)</span>
<span id="cb250-5"><a href="árboles-de-decisión.html#cb250-5" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(cs_scoreboard, <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modelo</th>
<th align="right">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Single Tree (caret)</td>
<td align="right">2.298331</td>
</tr>
<tr class="even">
<td align="left">Single Tree</td>
<td align="right">2.363202</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="bagged-trees" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Bagged trees<a href="árboles-de-decisión.html#bagged-trees" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los CART tiene una capacidad predictiva moderada, es por ello que se han propuesto unos métodos que combinan varios árboles de decisión para producir un mejor rendimiento predictivo que utilizar un solo árbol de decisión. El principio fundamental detrás de estos modelos es que un grupo de predictores débiles puede conseguir un predictor con mejor capacidad predictiva.</p>
<p>Tenemos dos tipos de estrategias:</p>
<ul>
<li><em>Bagging</em></li>
<li><em>Boosting</em></li>
</ul>
<blockquote>
<p>Bagging (Bootstrap Aggregation) se utiliza cuando nuestro objetivo es reducir la varianza de un árbol de decisión. La idea es crear varios subconjuntos de datos a partir de la muestra de entrenamiento elegida al azar con reemplazamiento. Cada subconjunto de datos se utiliza para entrenar un árbol de decisión. Como resultado, terminamos con un conjunto de diferentes modelos. Se utiliza el promedio de todas las predicciones de diferentes árboles, que es más robusto que considerar un solo árbol de decisión.</p>
</blockquote>
<div class="figure">
<img src="figures/bagged_tree.png" alt="" />
<p class="caption">Bagged trees</p>
</div>
<blockquote>
<p>En el Boosting se aprende de forma secuencial. Ajustamos árboles consecutivos (muestra aleatoria) y en cada paso, el objetivo es mejorar el error del árbol anterior.</p>
</blockquote>
<div class="figure">
<img src="figures/boosting.png" style="width:70.0%" alt="" />
<p class="caption">Boosted trees</p>
</div>
<p>Como hemos dicho anteriormente, el algoritmo <em>bagged</em> construye B árboles decisión usando conjuntos de entrenamiento obtenidos mediante remuestreo y promedia las predicciones resultantes. Estos árboles crecen profundamente y no se podan. Por tanto, cada árbol individual tiene una alta varianza, pero un bajo sesgo. Promediar los B árboles ayuda a reducir la varianza. El valor predicho para una observación es la moda (clasificación) o la media (regresión) de los árboles. B generalmente es igual a ~ 25.</p>
<div class="figure">
<img src="figures/bagged_tree_process.png" alt="" />
<p class="caption">Proceso para Bagged trees</p>
</div>
<p>Para un conjunto de entrenamiento de tamaño <span class="math inline">\(n\)</span>, cada árbol se compone de <span class="math inline">\(\sim (1 - e^{-1})n = .632n\)</span> observaciones únicas <em>in-bag</em> y <span class="math inline">\(.368n\)</span> <em>out-of-bag</em>. Las observaciones que no han sido seleccionadas en el re-muestreo se usan para evaluar la precisión del modelo. La capacidad glogal del método se obtiene promediando la capacidad de cada árbol. Esto tiene una <strong>desventaja obvia</strong> y es que si cada árbol tiene un rendimiento deficiente, el rendimiento promedio de muchos árboles seguirá siendo deficiente. Además, otra desventaja de este método es que no existe un árbol único con un conjunto de reglas para interpretar. En consecuencia, no queda claro qué variables son más importantes que otras y en algunos problemas (sobre todo biomédicos) esto puede ser una limitación importante.</p>
<div id="bagging-árboles-de-clasificación" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Bagging árboles de clasificación<a href="árboles-de-decisión.html#bagging-árboles-de-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Veamos de nuevo con un ejemplo cómo trabajar con estos métodos. Usaremos de nuevo los datos de zumos de naranja <code>OJ</code>. Esta vez usaremos un método <em>bagging</em> especificando <code>method="treebag"</code>. Caret no tiene hiperparámetros para este modelo, por lo que no es necesario usar <code>tuneLegth</code> ni <code>tuneGrid</code>. El tamaño de conjunto predeterminado es <code>nbagg = 25</code> (a veces se puede tunear, pero en este caso lo dejaremos fijo).</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="árboles-de-decisión.html#cb251-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb251-2"><a href="árboles-de-decisión.html#cb251-2" aria-hidden="true" tabindex="-1"></a>oj_mdl_bag <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb251-3"><a href="árboles-de-decisión.html#cb251-3" aria-hidden="true" tabindex="-1"></a>   Purchase <span class="sc">~</span> ., </span>
<span id="cb251-4"><a href="árboles-de-decisión.html#cb251-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> oj_train, </span>
<span id="cb251-5"><a href="árboles-de-decisión.html#cb251-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;treebag&quot;</span>,</span>
<span id="cb251-6"><a href="árboles-de-decisión.html#cb251-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> oj_trControl,</span>
<span id="cb251-7"><a href="árboles-de-decisión.html#cb251-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span></span>
<span id="cb251-8"><a href="árboles-de-decisión.html#cb251-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb251-9"><a href="árboles-de-decisión.html#cb251-9" aria-hidden="true" tabindex="-1"></a>oj_mdl_bag<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>
Bagging classification trees with 25 bootstrap replications </code></pre>
<p>Veamos el rendimiento en el conjunto de datos test.</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="árboles-de-decisión.html#cb253-1" aria-hidden="true" tabindex="-1"></a>pred_bag <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_bag, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>)</span>
<span id="cb253-2"><a href="árboles-de-decisión.html#cb253-2" aria-hidden="true" tabindex="-1"></a>oj_cm_bag <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_bag, oj_test<span class="sc">$</span>Purchase)</span>
<span id="cb253-3"><a href="árboles-de-decisión.html#cb253-3" aria-hidden="true" tabindex="-1"></a>oj_cm_bag</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  CH  MM
        CH 113  16
        MM  17  67
                                          
               Accuracy : 0.8451          
                 95% CI : (0.7894, 0.8909)
    No Information Rate : 0.6103          
    P-Value [Acc &gt; NIR] : 6.311e-14       
                                          
                  Kappa : 0.675           
                                          
 Mcnemar&#39;s Test P-Value : 1               
                                          
            Sensitivity : 0.8692          
            Specificity : 0.8072          
         Pos Pred Value : 0.8760          
         Neg Pred Value : 0.7976          
             Prevalence : 0.6103          
         Detection Rate : 0.5305          
   Detection Prevalence : 0.6056          
      Balanced Accuracy : 0.8382          
                                          
       &#39;Positive&#39; Class : CH              
                                          </code></pre>
<p>La precisión es 0.8451, sorprendentemente peor que el 0.85915 del modelo de árbol único, pero esa es una diferencia que corresponde a tres predicciones en un conjunto de 213. Esta sería la curva ROC.</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="árboles-de-decisión.html#cb255-1" aria-hidden="true" tabindex="-1"></a>pred_bag2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_bag, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[,<span class="st">&quot;CH&quot;</span>]</span>
<span id="cb255-2"><a href="árboles-de-decisión.html#cb255-2" aria-hidden="true" tabindex="-1"></a>roc.bag <span class="ot">&lt;-</span> <span class="fu">roc</span>(oj_test<span class="sc">$</span>Purchase, pred_bag2, <span class="at">print.auc=</span><span class="cn">TRUE</span>, </span>
<span id="cb255-3"><a href="árboles-de-decisión.html#cb255-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">ci=</span><span class="cn">TRUE</span>,</span>
<span id="cb255-4"><a href="árboles-de-decisión.html#cb255-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">plot=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-154-1.png" width="672" /></p>
<p>Veamos cuáles son las variables más importantes</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="árboles-de-decisión.html#cb256-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">varImp</span>(oj_mdl_bag), <span class="at">main=</span><span class="st">&quot;Importancia de variables con Bagging&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-155-1.png" width="672" /></p>
<p>Esta es la comparación entre métodos</p>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="árboles-de-decisión.html#cb257-1" aria-hidden="true" tabindex="-1"></a>oj_scoreboard <span class="ot">&lt;-</span> <span class="fu">rbind</span>(oj_scoreboard,</span>
<span id="cb257-2"><a href="árboles-de-decisión.html#cb257-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Bagging&quot;</span>, </span>
<span id="cb257-3"><a href="árboles-de-decisión.html#cb257-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">Accuracy =</span> oj_cm_bag<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>],</span>
<span id="cb257-4"><a href="árboles-de-decisión.html#cb257-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">ROC =</span> roc.bag<span class="sc">$</span>auc)</span>
<span id="cb257-5"><a href="árboles-de-decisión.html#cb257-5" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(ROC))</span>
<span id="cb257-6"><a href="árboles-de-decisión.html#cb257-6" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(oj_scoreboard, <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modelo</th>
<th align="right">Accuracy</th>
<th align="right">ROC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Single Tree (caret)</td>
<td align="right">0.8544601</td>
<td align="right">0.9162651</td>
</tr>
<tr class="even">
<td align="left">Bagging</td>
<td align="right">0.8450704</td>
<td align="right">0.9099166</td>
</tr>
<tr class="odd">
<td align="left">Single Tree</td>
<td align="right">0.8591549</td>
<td align="right">0.8848471</td>
</tr>
</tbody>
</table>
</div>
<div id="bagging-árboles-de-regresión" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Bagging árboles de regresión<a href="árboles-de-decisión.html#bagging-árboles-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Usemos <em>bagging</em> para predecir las ventas en los datos <code>Carseats</code>:</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="árboles-de-decisión.html#cb258-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb258-2"><a href="árboles-de-decisión.html#cb258-2" aria-hidden="true" tabindex="-1"></a>cs_mdl_bag <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb258-3"><a href="árboles-de-decisión.html#cb258-3" aria-hidden="true" tabindex="-1"></a>   Sales <span class="sc">~</span> ., </span>
<span id="cb258-4"><a href="árboles-de-decisión.html#cb258-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> cs_train, </span>
<span id="cb258-5"><a href="árboles-de-decisión.html#cb258-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;treebag&quot;</span>,</span>
<span id="cb258-6"><a href="árboles-de-decisión.html#cb258-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> cs_trControl</span>
<span id="cb258-7"><a href="árboles-de-decisión.html#cb258-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb258-8"><a href="árboles-de-decisión.html#cb258-8" aria-hidden="true" tabindex="-1"></a>cs_mdl_bag</span></code></pre></div>
<pre><code>Bagged CART 

321 samples
 10 predictor

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 289, 289, 289, 289, 289, 289, ... 
Resampling results:

  RMSE      Rsquared  MAE     
  1.681889  0.675239  1.343427</code></pre>
<p>Veamos el rendimiento en el conjunto de datos test. El RMSE es 1.9185, pero el modelo predice en exceso en el extremo inferior de ventas y tampoco predice bien en el extremo superior (como un árbol simple).</p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="árboles-de-decisión.html#cb260-1" aria-hidden="true" tabindex="-1"></a>cs_preds_bag <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(</span>
<span id="cb260-2"><a href="árboles-de-decisión.html#cb260-2" aria-hidden="true" tabindex="-1"></a>   <span class="at">Predicted =</span> <span class="fu">predict</span>(cs_mdl_bag, <span class="at">newdata =</span> cs_test),</span>
<span id="cb260-3"><a href="árboles-de-decisión.html#cb260-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">Actual =</span> cs_test<span class="sc">$</span>Sales</span>
<span id="cb260-4"><a href="árboles-de-decisión.html#cb260-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb260-5"><a href="árboles-de-decisión.html#cb260-5" aria-hidden="true" tabindex="-1"></a>(cs_rmse_bag <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(<span class="at">pred =</span> cs_preds_bag<span class="sc">$</span>Predicted, <span class="at">obs =</span> cs_preds_bag<span class="sc">$</span>Actual))</span></code></pre></div>
<pre><code>[1] 1.918473</code></pre>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="árboles-de-decisión.html#cb262-1" aria-hidden="true" tabindex="-1"></a>cs_preds_bag <span class="sc">%&gt;%</span></span>
<span id="cb262-2"><a href="árboles-de-decisión.html#cb262-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Actual, <span class="at">y =</span> Predicted)) <span class="sc">+</span></span>
<span id="cb262-3"><a href="árboles-de-decisión.html#cb262-3" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">&quot;cadetblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb262-4"><a href="árboles-de-decisión.html#cb262-4" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="at">formula =</span> <span class="st">&quot;y ~ x&quot;</span>) <span class="sc">+</span></span>
<span id="cb262-5"><a href="árboles-de-decisión.html#cb262-5" aria-hidden="true" tabindex="-1"></a>   <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">0</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">linetype =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb262-6"><a href="árboles-de-decisión.html#cb262-6" aria-hidden="true" tabindex="-1"></a>   <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Carseats Bagging, Predicted vs Actual (caret)&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-159-1.png" width="672" /></p>
<p>La importancia de las variables son:</p>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="árboles-de-decisión.html#cb263-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">varImp</span>(cs_mdl_bag), <span class="at">main=</span><span class="st">&quot;Importancia de variables con Bagging&quot;</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-160-1.png" width="672" /></p>
<p>Y la comparación quedaría</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="árboles-de-decisión.html#cb264-1" aria-hidden="true" tabindex="-1"></a>cs_scoreboard <span class="ot">&lt;-</span> <span class="fu">rbind</span>(cs_scoreboard,</span>
<span id="cb264-2"><a href="árboles-de-decisión.html#cb264-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Bagging&quot;</span>, <span class="at">RMSE =</span> cs_rmse_bag)</span>
<span id="cb264-3"><a href="árboles-de-decisión.html#cb264-3" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(RMSE)</span>
<span id="cb264-4"><a href="árboles-de-decisión.html#cb264-4" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(cs_scoreboard, <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modelo</th>
<th align="right">RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Bagging</td>
<td align="right">1.918473</td>
</tr>
<tr class="even">
<td align="left">Single Tree (caret)</td>
<td align="right">2.298331</td>
</tr>
<tr class="odd">
<td align="left">Single Tree</td>
<td align="right">2.363202</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="random-forest" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Random Forest<a href="árboles-de-decisión.html#random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los <em>Random Forest</em> (bosques aleatorios) también son un conjunto de árboles de decisión (<em>ensambladores</em>) que mejoran los <em>bagged trees</em> mediante la creación de un bosque no correlacionados de árboles que, de nuevo, mejora la capacidad predictiva de un único árbol. Al igual que en el <em>bagged</em> (<em>embolsado</em>), el algoritmo construye varios árboles de decisión sobre muestras de entrenamiento bootstrap. Sin embargo, al construir estos árboles de decisión, cada vez que se considera una división en un árbol, se elige una muestra aleatoria de predictores (hiperparámetro <em>m</em> o <em>mtry</em>) como candidatos de división del conjunto completo de predictores <span class="math inline">\(p\)</span>. En cada división se toma una nueva muestra de predictores. Típicamente <span class="math inline">\(m \approx \sqrt{p}\)</span>. En consecuencia, los árboles <em>bagged</em> son un caso especial de los <em>random forest</em> cuando <span class="math inline">\(m = p\)</span>.</p>
<p>Cada árbol del modelo <em>random forest</em> se construye de la siguiente forma:</p>
<ul>
<li><p>Si denotamos por <span class="math inline">\(N\)</span> el número de casos en el conjunto de entrenamiento, seleccionaremos una muestra de esos <span class="math inline">\(N\)</span> casos se forma aleatoria CON REEMPLAZAMIENTO. Esta muestra será el conjunto de entrenamiento para construir el árbol i-ésimo.</p></li>
<li><p>Si denotamos por <span class="math inline">\(M\)</span> el número total de varibles predictoras, seleccionaremos un número <span class="math inline">\(m &lt; M\)</span> de variables y crearemos un árbol completo con esas variables. El valor <span class="math inline">\(m\)</span> se mantiene constante durante la generación de todo el bosque.</p></li>
<li><p>Cada árbol crece hasta su máxima extensión posible y NO hay proceso de poda.</p></li>
<li><p>La predicción para nuevos individuos se hace a partir de la información obtenida de las predicciones de los <span class="math inline">\(B\)</span> árboles (mayoría de votos para clasificación, promedio para regresión). La siguiente figura ilustra este proceso</p></li>
</ul>
<div class="figure">
<img src="figures/random_forest.png" alt="" />
<p class="caption">Random Forest</p>
</div>
<p>Podemos estimar un <em>random forest</em> con <code>cart</code> indicando el argumento <code>method = "rf"</code>. El hiperparámetro <code>mtry</code> (<span class="math inline">\(m\)</span>) puede tomar cualquier valor de 1 a 17 (el número de predictores) y se espera que el valor óptimo esté cerca de <span class="math inline">\(\sqrt{17} \approx 4\)</span>. En cuanto al número de árboles (segundo hiperparámetro), hay estudios que demuestran que el rendimiento empeora cuando tenemos muchos árboles, sin embargo esto no está muy claro y por lo general se recomienda entrenar modelos con muchos árboles. Por defecto <code>method = "rf"</code> tiene 500 (argumento <code>num.trees</code>).</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="árboles-de-decisión.html#cb265-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb265-2"><a href="árboles-de-decisión.html#cb265-2" aria-hidden="true" tabindex="-1"></a>oj_mdl_rf <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb265-3"><a href="árboles-de-decisión.html#cb265-3" aria-hidden="true" tabindex="-1"></a>   Purchase <span class="sc">~</span> ., </span>
<span id="cb265-4"><a href="árboles-de-decisión.html#cb265-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> oj_train, </span>
<span id="cb265-5"><a href="árboles-de-decisión.html#cb265-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>,</span>
<span id="cb265-6"><a href="árboles-de-decisión.html#cb265-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb265-7"><a href="árboles-de-decisión.html#cb265-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">mtry =</span> <span class="dv">3</span><span class="sc">:</span><span class="dv">10</span>),</span>
<span id="cb265-8"><a href="árboles-de-decisión.html#cb265-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">trControl =</span> oj_trControl,</span>
<span id="cb265-9"><a href="árboles-de-decisión.html#cb265-9" aria-hidden="true" tabindex="-1"></a>   <span class="at">num.trees =</span> <span class="dv">500</span></span>
<span id="cb265-10"><a href="árboles-de-decisión.html#cb265-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb265-11"><a href="árboles-de-decisión.html#cb265-11" aria-hidden="true" tabindex="-1"></a>oj_mdl_rf</span></code></pre></div>
<pre><code>Random Forest 

857 samples
 17 predictor
  2 classes: &#39;CH&#39;, &#39;MM&#39; 

No pre-processing
Resampling: Cross-Validated (10 fold) 
Summary of sample sizes: 772, 772, 771, 770, 771, 771, ... 
Resampling results across tuning parameters:

  mtry  ROC        Sens       Spec     
   3    0.8655672  0.8565312  0.7185383
   4    0.8685845  0.8641872  0.7122995
   5    0.8682630  0.8470247  0.7183601
   6    0.8672458  0.8412917  0.7124777
   7    0.8695796  0.8412917  0.7183601
   8    0.8668721  0.8393687  0.7213012
   9    0.8652269  0.8432148  0.7153298
  10    0.8671443  0.8413280  0.7152406

ROC was used to select the optimal model using the largest value.
The final value used for the model was mtry = 7.</code></pre>
<p>El valor de ROC más alto se da en <span class="math inline">\(m = 7\)</span> que es más alto de lo que esperábamos, pero fijémosnos que es un valor de ROC muy similar al que se obtiene con <span class="math inline">\(m=4\)</span>, por lo que por el principio de parsimonia podríamos usar dicho valor</p>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="árboles-de-decisión.html#cb267-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(oj_mdl_rf)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-163-1.png" width="672" /></p>
<p>También podemos visualizar los resultados con:</p>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="árboles-de-decisión.html#cb268-1" aria-hidden="true" tabindex="-1"></a>plot_rf <span class="ot">&lt;-</span> <span class="cf">function</span>(model) {</span>
<span id="cb268-2"><a href="árboles-de-decisión.html#cb268-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())</span>
<span id="cb268-3"><a href="árboles-de-decisión.html#cb268-3" aria-hidden="true" tabindex="-1"></a>    u <span class="ot">&lt;-</span> model<span class="sc">$</span>results <span class="sc">%&gt;%</span></span>
<span id="cb268-4"><a href="árboles-de-decisión.html#cb268-4" aria-hidden="true" tabindex="-1"></a>        dplyr<span class="sc">::</span><span class="fu">select</span>(mtry, ROC, Sens, Spec) <span class="sc">%&gt;%</span></span>
<span id="cb268-5"><a href="árboles-de-decisión.html#cb268-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">gather</span>(a, b, <span class="sc">-</span>mtry)</span>
<span id="cb268-6"><a href="árboles-de-decisión.html#cb268-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb268-7"><a href="árboles-de-decisión.html#cb268-7" aria-hidden="true" tabindex="-1"></a>    u <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(mtry, b)) <span class="sc">+</span> <span class="fu">geom_line</span>() <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb268-8"><a href="árboles-de-decisión.html#cb268-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">facet_wrap</span>(<span class="sc">~</span> a, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span> </span>
<span id="cb268-9"><a href="árboles-de-decisión.html#cb268-9" aria-hidden="true" tabindex="-1"></a>        <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Número de predictores&quot;</span>, <span class="at">y =</span> <span class="cn">NULL</span>, </span>
<span id="cb268-10"><a href="árboles-de-decisión.html#cb268-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">title =</span> <span class="st">&quot;Relación entre el número de predictores y el comportamiento del modelo&quot;</span>)</span>
<span id="cb268-11"><a href="árboles-de-decisión.html#cb268-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb268-12"><a href="árboles-de-decisión.html#cb268-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb268-13"><a href="árboles-de-decisión.html#cb268-13" aria-hidden="true" tabindex="-1"></a>oj_mdl_rf <span class="sc">%&gt;%</span> <span class="fu">plot_rf</span>()</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-164-1.png" width="672" /></p>
<p>Podemos usar este modelo para hacer predicciones sobre la muestra test</p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="árboles-de-decisión.html#cb269-1" aria-hidden="true" tabindex="-1"></a>pred_rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_rf, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>)</span>
<span id="cb269-2"><a href="árboles-de-decisión.html#cb269-2" aria-hidden="true" tabindex="-1"></a>oj_cm_rf <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(pred_rf, oj_test<span class="sc">$</span>Purchase)</span>
<span id="cb269-3"><a href="árboles-de-decisión.html#cb269-3" aria-hidden="true" tabindex="-1"></a>oj_cm_rf</span></code></pre></div>
<pre><code>Confusion Matrix and Statistics

          Reference
Prediction  CH  MM
        CH 112  16
        MM  18  67
                                          
               Accuracy : 0.8404          
                 95% CI : (0.7841, 0.8869)
    No Information Rate : 0.6103          
    P-Value [Acc &gt; NIR] : 2.164e-13       
                                          
                  Kappa : 0.6659          
                                          
 Mcnemar&#39;s Test P-Value : 0.8638          
                                          
            Sensitivity : 0.8615          
            Specificity : 0.8072          
         Pos Pred Value : 0.8750          
         Neg Pred Value : 0.7882          
             Prevalence : 0.6103          
         Detection Rate : 0.5258          
   Detection Prevalence : 0.6009          
      Balanced Accuracy : 0.8344          
                                          
       &#39;Positive&#39; Class : CH              
                                          </code></pre>
<p>Y el área bajo la curva ROC sería:</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="árboles-de-decisión.html#cb271-1" aria-hidden="true" tabindex="-1"></a>pred_rf2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(oj_mdl_rf, <span class="at">newdata =</span> oj_test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[,<span class="st">&quot;CH&quot;</span>]</span>
<span id="cb271-2"><a href="árboles-de-decisión.html#cb271-2" aria-hidden="true" tabindex="-1"></a>roc.rf <span class="ot">&lt;-</span> <span class="fu">roc</span>(oj_test<span class="sc">$</span>Purchase, pred_bag2, <span class="at">print.auc=</span><span class="cn">TRUE</span>, </span>
<span id="cb271-3"><a href="árboles-de-decisión.html#cb271-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">ci=</span><span class="cn">TRUE</span>,</span>
<span id="cb271-4"><a href="árboles-de-decisión.html#cb271-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">plot=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="fig_out/unnamed-chunk-166-1.png" width="672" /></p>
<p>que compara con los modelos anteriores de esta forma:</p>
<p>Y la comparación quedaría</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="árboles-de-decisión.html#cb272-1" aria-hidden="true" tabindex="-1"></a>oj_scoreboard <span class="ot">&lt;-</span> <span class="fu">rbind</span>(oj_scoreboard,</span>
<span id="cb272-2"><a href="árboles-de-decisión.html#cb272-2" aria-hidden="true" tabindex="-1"></a>   <span class="fu">data.frame</span>(<span class="at">Modelo =</span> <span class="st">&quot;Random Forest&quot;</span>, </span>
<span id="cb272-3"><a href="árboles-de-decisión.html#cb272-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">Accuracy =</span> oj_cm_rf<span class="sc">$</span>overall[<span class="st">&quot;Accuracy&quot;</span>],</span>
<span id="cb272-4"><a href="árboles-de-decisión.html#cb272-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">ROC =</span> roc.rf<span class="sc">$</span>auc)</span>
<span id="cb272-5"><a href="árboles-de-decisión.html#cb272-5" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(ROC))</span>
<span id="cb272-6"><a href="árboles-de-decisión.html#cb272-6" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(oj_scoreboard, <span class="at">row.names =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Modelo</th>
<th align="right">Accuracy</th>
<th align="right">ROC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Single Tree (caret)</td>
<td align="right">0.8544601</td>
<td align="right">0.9162651</td>
</tr>
<tr class="even">
<td align="left">Bagging</td>
<td align="right">0.8450704</td>
<td align="right">0.9099166</td>
</tr>
<tr class="odd">
<td align="left">Random Forest</td>
<td align="right">0.8403756</td>
<td align="right">0.9099166</td>
</tr>
<tr class="even">
<td align="left">Single Tree</td>
<td align="right">0.8591549</td>
<td align="right">0.8848471</td>
</tr>
</tbody>
</table>
<p>Recordemos que la importancia de las variables se puede ver con la función <code>varImp</code> al igual que cualquier otro modelo basado en àrboles de decisión.</p>
<p><strong>NOTA:</strong> El ejemplo para Random Forest con árboles de regresión es igual que lo que vimos en la sección anterior.</p>
<p><strong>NOTA2:</strong> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7508310/">En este artículo</a> se hace un “benchmarking” muy interesante para saber qué método y libería de R usar en función de las características de nuestro conjunto de datos.</p>
<p>Speiser JL et al. (2012). <strong>A Comparison of Random Forest Variable Selection Methods for Classification Prediction Modeling</strong></p>
<blockquote>
<p>Random forest classification is a popular machine learning method for developing prediction models in many research settings. Often in prediction modeling, a goal is to reduce the number of variables needed to obtain a prediction in order to reduce the burden of data collection and improve efficiency. Several variable selection methods exist for the setting of random forest classification; however, there is a paucity of literature to guide users as to which method may be preferable for different types of datasets. Using 311 classification datasets freely available online, we evaluate the prediction error rates, number of variables, computation times and area under the receiver operating curve for many random forest variable selection methods. We compare random forest variable selection methods for different types of datasets (datasets with binary outcomes, datasets with many predictors, and datasets with imbalanced outcomes) and for different types of methods (standard random forest versus conditional random forest methods and test based versus performance based methods). Based on our study, the best variable selection methods for most datasets are Jiang’s method and the method implemented in the VSURF R package. For datasets with many predictors, the methods implemented in the R packages varSelRF and Boruta are preferable due to computational efficiency. A significant contribution of this study is the ability to assess different variable selection techniques in the setting of random forest classification in order to identify preferable methods based on applications in expert and intelligent systems.</p>
</blockquote>
</div>
<div id="random-forest-pn" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Random Forest p&gt;&gt;n<a href="árboles-de-decisión.html#random-forest-pn" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Problema</strong>: Aplicar Random Forest para conjunto de datos con muchas variables (caso p&gt;&gt;n)</p>
<ul>
<li><strong>Posible estrategia</strong>:</li>
</ul>
<ol style="list-style-type: decimal">
<li>Creamos K subconjuntos de variable</li>
<li>Llevamos a cabo una selección de las variables más importantes y nos quedamos con una parte de ellas. Por ejemplo, las M más informativas</li>
<li>Combinamos las K*M variables y repetimos los pasos 1 y 2</li>
<li>Acabamos con M variables seleccionadas</li>
<li>Aplicamos Random Forest</li>
</ol>
<p>Este enfoque podría causar la pérdida de algunas variables importantes, pero generalmente seleccionará las variables más informativas.</p>
<p>Selección de K y M
<a href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf">Breiman (2001)</a> recomienda <span class="math inline">\(m=p/3\)</span> en clasificación y <span class="math inline">\(m=\sqrt{p}\)</span> en regresión (mtry). ¿Puede servir esto de ayuda?</p>
<ul>
<li><p><a href="https://cran.r-project.org/web/packages/RRF/RRF.pdf">Reguralized Random Forest</a></p></li>
<li><p><a href="thttps://www.sciencedirect.com/science/article/abs/pii/S0031320313002422">Guided Regularized Random Forest</a></p></li>
<li><p><strong>Otra opción</strong>: Librería <a href="https://www.jstatsoft.org/article/view/v077i01">ranger</a></p></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="caret.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="boosting.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/isglobal-brge/curso_machine_learning/tree/master/docs05-arboles_decision.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
